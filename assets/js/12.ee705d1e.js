(window.webpackJsonp=window.webpackJsonp||[]).push([[12],{256:function(t,a,s){"use strict";s.r(a);var n=s(28),e=Object(n.a)({},(function(){var t=this,a=t.$createElement,s=t._self._c||a;return s("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[s("h1",{attrs:{id:"_2-数据模型与查询语言"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-数据模型与查询语言"}},[t._v("#")]),t._v(" 2. 数据模型与查询语言")]),t._v(" "),s("p",[s("img",{attrs:{src:"img/ch2.png",alt:""}})]),t._v(" "),s("blockquote",[s("p",[t._v("语言的边界就是思想的边界。")]),t._v(" "),s("p",[t._v("—— 路德维奇·维特根斯坦，《逻辑哲学》（1922）")])]),t._v(" "),s("hr"),t._v(" "),s("p",[t._v("[TOC]")]),t._v(" "),s("p",[t._v("数据模型可能是软件开发中最重要的部分了，因为它们的影响如此深远：不仅仅影响着软件的编写方式，而且影响着我们的"),s("strong",[t._v("解题思路")]),t._v("。")]),t._v(" "),s("p",[t._v("多数应用使用层层叠加的数据模型构建。对于每层数据模型的关键问题是：它是如何用低一层数据模型来"),s("strong",[t._v("表示")]),t._v("的？例如：")]),t._v(" "),s("ol",[s("li",[t._v("作为一名应用开发人员，你观察现实世界（里面有人员，组织，货物，行为，资金流向，传感器等），并采用对象或数据结构，以及操控那些数据结构的API来进行建模。那些结构通常是特定于应用程序的。")]),t._v(" "),s("li",[t._v("当要存储那些数据结构时，你可以利用通用数据模型来表示它们，如JSON或XML文档，关系数据库中的表、或图模型。")]),t._v(" "),s("li",[t._v("数据库软件的工程师选定如何以内存、磁盘或网络上的字节来表示JSON/XML/关系/图数据。这类表示形式使数据有可能以各种方式来查询，搜索，操纵和处理。")]),t._v(" "),s("li",[t._v("在更低的层次上，硬件工程师已经想出了使用电流，光脉冲，磁场或者其他东西来表示字节的方法。")])]),t._v(" "),s("p",[t._v("一个复杂的应用程序可能会有更多的中间层次，比如基于API的API，不过基本思想仍然是一样的：每个层都通过提供一个明确的数据模型来隐藏更低层次中的复杂性。这些抽象允许不同的人群有效地协作（例如数据库厂商的工程师和使用数据库的应用程序开发人员）。")]),t._v(" "),s("p",[t._v("数据模型种类繁多，每个数据模型都带有如何使用的设想。有些用法很容易，有些则不支持如此；有些操作运行很快，有些则表现很差；有些数据转换非常自然，有些则很麻烦。")]),t._v(" "),s("p",[t._v("掌握一个数据模型需要花费很多精力（想想关系数据建模有多少本书）。即便只使用一个数据模型，不用操心其内部工作机制，构建软件也是非常困难的。然而，因为数据模型对上层软件的功能（能做什么，不能做什么）有着至深的影响，所以选择一个适合的数据模型是非常重要的。")]),t._v(" "),s("p",[t._v("在本章中，我们将研究一系列用于数据存储和查询的通用数据模型（前面列表中的第2点）。特别地，我们将比较关系模型，文档模型和少量基于图形的数据模型。我们还将查看各种查询语言并比较它们的用例。在第3章中，我们将讨论存储引擎是如何工作的。也就是说，这些数据模型实际上是如何实现的（列表中的第3点）。")]),t._v(" "),s("h2",{attrs:{id:"关系模型与文档模型"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#关系模型与文档模型"}},[t._v("#")]),t._v(" 关系模型与文档模型")]),t._v(" "),s("p",[t._v("现在最著名的数据模型可能是SQL。它基于Edgar Codd在1970年提出的关系模型【1】：数据被组织成"),s("strong",[t._v("关系")]),t._v("（SQL中称作"),s("strong",[t._v("表")]),t._v("），其中每个关系是"),s("strong",[t._v("元组")]),t._v("（SQL中称作"),s("strong",[t._v("行")]),t._v(")的无序集合。")]),t._v(" "),s("p",[t._v("关系模型曾是一个理论性的提议，当时很多人都怀疑是否能够有效实现它。然而到了20世纪80年代中期，关系数据库管理系统（RDBMSes）和SQL已成为大多数人们存储和查询某些常规结构的数据的首选工具。关系数据库已经持续称霸了大约25~30年——这对计算机史来说是极其漫长的时间。")]),t._v(" "),s("p",[t._v("关系数据库起源于商业数据处理，在20世纪60年代和70年代用大型计算机来执行。从今天的角度来看，那些用例显得很平常：典型的"),s("strong",[t._v("事务处理")]),t._v("（将销售或银行交易，航空公司预订，库存管理信息记录在库）和"),s("strong",[t._v("批处理")]),t._v("（客户发票，工资单，报告）。")]),t._v(" "),s("p",[t._v("当时的其他数据库迫使应用程序开发人员必须考虑数据库内部的数据表示形式。关系模型致力于将上述实现细节隐藏在更简洁的接口之后。")]),t._v(" "),s("p",[t._v("多年来，在数据存储和查询方面存在着许多相互竞争的方法。在20世纪70年代和80年代初，网络模型和分层模型曾是主要的选择，但关系模型随后占据了主导地位。对象数据库在20世纪80年代末和90年代初来了又去。XML数据库在二十一世纪初出现，但只有小众采用过。关系模型的每个竞争者都在其时代产生了大量的炒作，但从来没有持续【2】。")]),t._v(" "),s("p",[t._v("随着电脑越来越强大和互联，它们开始用于日益多样化的目的。关系数据库非常成功地被推广到业务数据处理的原始范围之外更为广泛的用例上。你今天在网上看到的大部分内容依旧是由关系数据库来提供支持，无论是在线发布，讨论，社交网络，电子商务，游戏，软件即服务生产力应用程序等等内容。")]),t._v(" "),s("h3",{attrs:{id:"nosql的诞生"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#nosql的诞生"}},[t._v("#")]),t._v(" NoSQL的诞生")]),t._v(" "),s("p",[t._v("现在 - 2010年代，NoSQL开始了最新一轮尝试，试图推翻关系模型的统治地位。“NoSQL”这个名字让人遗憾，因为实际上它并没有涉及到任何特定的技术。最初它只是作为一个醒目的Twitter标签，用在2009年一个关于分布式，非关系数据库上的开源聚会上。无论如何，这个术语触动了某些神经，并迅速在网络创业社区内外传播开来。好些有趣的数据库系统现在都与*#NoSQL#*标签相关联，并且NoSQL被追溯性地重新解释为"),s("strong",[t._v("不仅是SQL（Not Only SQL）")]),t._v(" 【4】。")]),t._v(" "),s("p",[t._v("采用NoSQL数据库的背后有几个驱动因素，其中包括：")]),t._v(" "),s("ul",[s("li",[t._v("需要比关系数据库更好的可扩展性，包括非常大的数据集或非常高的写入吞吐量")]),t._v(" "),s("li",[t._v("相比商业数据库产品，免费和开源软件更受偏爱。")]),t._v(" "),s("li",[t._v("关系模型不能很好地支持一些特殊的查询操作")]),t._v(" "),s("li",[t._v("受挫于关系模型的限制性，渴望一种更具多动态性与表现力的数据模型【5】")])]),t._v(" "),s("p",[t._v("不同的应用程序有不同的需求，一个用例的最佳技术选择可能不同于另一个用例的最佳技术选择。因此，在可预见的未来，关系数据库似乎可能会继续与各种非关系数据库一起使用 - 这种想法有时也被称为"),s("strong",[t._v("混合持久化（polyglot persistence）")])]),t._v(" "),s("h3",{attrs:{id:"对象关系不匹配"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#对象关系不匹配"}},[t._v("#")]),t._v(" 对象关系不匹配")]),t._v(" "),s("p",[t._v("目前大多数应用程序开发都使用面向对象的编程语言来开发，这导致了对SQL数据模型的普遍批评：如果数据存储在关系表中，那么需要一个笨拙的转换层，处于应用程序代码中的对象和表，行，列的数据库模型之间。模型之间的不连贯有时被称为"),s("strong",[t._v("阻抗不匹配（impedance mismatch）")]),s("a",{attrs:{href:"%E4%B8%80%E4%B8%AA%E4%BB%8E%E7%94%B5%E5%AD%90%E5%AD%A6%E5%80%9F%E7%94%A8%E7%9A%84%E6%9C%AF%E8%AF%AD%E3%80%82%E6%AF%8F%E4%B8%AA%E7%94%B5%E8%B7%AF%E7%9A%84%E8%BE%93%E5%85%A5%E5%92%8C%E8%BE%93%E5%87%BA%E9%83%BD%E6%9C%89%E4%B8%80%E5%AE%9A%E7%9A%84%E9%98%BB%E6%8A%97%EF%BC%88%E4%BA%A4%E6%B5%81%E7%94%B5%E9%98%BB%EF%BC%89%E3%80%82%E5%BD%93%E4%BD%A0%E5%B0%86%E4%B8%80%E4%B8%AA%E7%94%B5%E8%B7%AF%E7%9A%84%E8%BE%93%E5%87%BA%E8%BF%9E%E6%8E%A5%E5%88%B0%E5%8F%A6%E4%B8%80%E4%B8%AA%E7%94%B5%E8%B7%AF%E7%9A%84%E8%BE%93%E5%85%A5%E6%97%B6%EF%BC%8C%E5%A6%82%E6%9E%9C%E4%B8%A4%E4%B8%AA%E7%94%B5%E8%B7%AF%E7%9A%84%E8%BE%93%E5%87%BA%E5%92%8C%E8%BE%93%E5%85%A5%E9%98%BB%E6%8A%97%E5%8C%B9%E9%85%8D%EF%BC%8C%E5%88%99%E8%BF%9E%E6%8E%A5%E4%B8%8A%E7%9A%84%E5%8A%9F%E7%8E%87%E4%BC%A0%E8%BE%93%E5%B0%86%E8%A2%AB%E6%9C%80%E5%A4%A7%E5%8C%96%E3%80%82%E9%98%BB%E6%8A%97%E4%B8%8D%E5%8C%B9%E9%85%8D%E4%BC%9A%E5%AF%BC%E8%87%B4%E4%BF%A1%E5%8F%B7%E5%8F%8D%E5%B0%84%E5%8F%8A%E5%85%B6%E4%BB%96%E9%97%AE%E9%A2%98%E3%80%82"}},[t._v("^i")]),t._v("。")]),t._v(" "),s("p",[t._v("像ActiveRecord和Hibernate这样的 "),s("strong",[t._v("对象关系映射（ORM object-relational mapping）")]),t._v(" 框架可以减少这个转换层所需的样板代码的数量，但是它们不能完全隐藏这两个模型之间的差异。")]),t._v(" "),s("p",[s("img",{attrs:{src:"img/fig2-1.png",alt:""}})]),t._v(" "),s("p",[s("strong",[t._v("图2-1 使用关系型模式来表示领英简介")])]),t._v(" "),s("p",[t._v("例如，"),s("a",{attrs:{href:"img/fig2-1.png"}},[t._v("图2-1")]),t._v("展示了如何在关系模式中表示简历（一个LinkedIn简介）。整个简介可以通过一个唯一的标识符"),s("code",[t._v("user_id")]),t._v("来标识。像"),s("code",[t._v("first_name")]),t._v("和"),s("code",[t._v("last_name")]),t._v("这样的字段每个用户只出现一次，所以可以在User表上将其建模为列。但是，大多数人在职业生涯中拥有多于一份的工作，人们可能有不同样的教育阶段和任意数量的联系信息。从用户到这些项目之间存在一对多的关系，可以用多种方式来表示：")]),t._v(" "),s("ul",[s("li",[t._v("传统SQL模型（SQL：1999之前）中，最常见的规范化表示形式是将职位，教育和联系信息放在单独的表中，对User表提供外键引用，如"),s("a",{attrs:{href:"img/fig2-1.png"}},[t._v("图2-1")]),t._v("所示。")]),t._v(" "),s("li",[t._v("后续的SQL标准增加了对结构化数据类型和XML数据的支持;这允许将多值数据存储在单行内，并支持在这些文档内查询和索引。这些功能在Oracle，IBM DB2，MS SQL Server和PostgreSQL中都有不同程度的支持【6,7】。JSON数据类型也得到多个数据库的支持，包括IBM DB2，MySQL和PostgreSQL 【8】。")]),t._v(" "),s("li",[t._v("第三种选择是将职业，教育和联系信息编码为JSON或XML文档，将其存储在数据库的文本列中，并让应用程序解析其结构和内容。这种配置下，通常不能使用数据库来查询该编码列中的值。")])]),t._v(" "),s("p",[t._v("对于一个像简历这样自包含文档的数据结构而言，JSON表示是非常合适的：参见"),s("a",{attrs:{href:""}},[t._v("例2-1")]),t._v("。JSON比XML更简单。面向文档的数据库（如MongoDB 【9】，RethinkDB 【10】，CouchDB 【11】和Espresso【12】）支持这种数据模型。\n"),s("strong",[t._v("例2-1. 用JSON文档表示一个LinkedIn简介")])]),t._v(" "),s("div",{staticClass:"language-json extra-class"},[s("pre",{pre:!0,attrs:{class:"language-json"}},[s("code",[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token property"}},[t._v('"user_id"')]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("251")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token property"}},[t._v('"first_name"')]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Bill"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token property"}},[t._v('"last_name"')]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Gates"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token property"}},[t._v('"summary"')]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Co-chair of the Bill & Melinda Gates... Active blogger."')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token property"}},[t._v('"region_id"')]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"us:91"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token property"}},[t._v('"industry_id"')]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("131")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token property"}},[t._v('"photo_url"')]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"/p/7/000/253/05b/308dd6e.jpg"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token property"}},[t._v('"positions"')]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token property"}},[t._v('"job_title"')]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Co-chair"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token property"}},[t._v('"organization"')]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Bill & Melinda Gates Foundation"')]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token property"}},[t._v('"job_title"')]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Co-founder, Chairman"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token property"}},[t._v('"organization"')]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Microsoft"')]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token property"}},[t._v('"education"')]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token property"}},[t._v('"school_name"')]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Harvard University"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token property"}},[t._v('"start"')]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1973")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token property"}},[t._v('"end"')]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1975")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token property"}},[t._v('"school_name"')]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Lakeside School, Seattle"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token property"}},[t._v('"start"')]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token null keyword"}},[t._v("null")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token property"}},[t._v('"end"')]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token null keyword"}},[t._v("null")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token property"}},[t._v('"contact_info"')]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token property"}},[t._v('"blog"')]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"http://thegatesnotes.com"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token property"}},[t._v('"twitter"')]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"http://twitter.com/BillGates"')]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),s("p",[t._v("有一些开发人员认为JSON模型减少了应用程序代码和存储层之间的阻抗不匹配。不过，正如我们将在"),s("RouterLink",{attrs:{to:"/ddia/ch4.html"}},[t._v("第4章")]),t._v("中看到的那样，JSON作为数据编码格式也存在问题。缺乏一个模式往往被认为是一个优势;我们将在“"),s("a",{attrs:{href:"#%E6%96%87%E6%A1%A3%E6%A8%A1%E5%9E%8B%E4%B8%AD%E7%9A%84%E6%A8%A1%E5%BC%8F%E7%81%B5%E6%B4%BB%E6%80%A7"}},[t._v("文档模型中的模式灵活性")]),t._v("”中讨论这个问题。")],1),t._v(" "),s("p",[t._v("JSON表示比"),s("a",{attrs:{href:"img/fig2-1.png"}},[t._v("图2-1")]),t._v("中的多表模式具有更好的"),s("strong",[t._v("局部性（locality）")]),t._v("。如果在前面的关系型示例中获取简介，那需要执行多个查询（通过"),s("code",[t._v("user_id")]),t._v("查询每个表），或者在User表与其下属表之间混乱地执行多路连接。而在JSON表示中，所有相关信息都在同一个地方，一个查询就足够了。")]),t._v(" "),s("p",[t._v("从用户简介文件到用户职位，教育历史和联系信息，这种一对多关系隐含了数据中的一个树状结构，而JSON表示使得这个树状结构变得明确（见"),s("a",{attrs:{href:"img/fig2-2.png"}},[t._v("图2-2")]),t._v("）。")]),t._v(" "),s("p",[s("img",{attrs:{src:"img/fig2-2.png",alt:""}})]),t._v(" "),s("p",[s("strong",[t._v("图2-2 一对多关系构建了一个树结构")])]),t._v(" "),s("h3",{attrs:{id:"多对一和多对多的关系"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#多对一和多对多的关系"}},[t._v("#")]),t._v(" 多对一和多对多的关系")]),t._v(" "),s("p",[t._v("在上一节的"),s("a",{attrs:{href:""}},[t._v("例2-1")]),t._v("中，"),s("code",[t._v("region_id")]),t._v("和"),s("code",[t._v("industry_id")]),t._v("是以ID，而不是纯字符串“Greater Seattle Area”和“Philanthropy”的形式给出的。为什么？")]),t._v(" "),s("p",[t._v("如果用户界面用一个自由文本字段来输入区域和行业，那么将他们存储为纯文本字符串是合理的。另一方式是给出地理区域和行业的标准化的列表，并让用户从下拉列表或自动填充器中进行选择，其优势如下：")]),t._v(" "),s("ul",[s("li",[t._v("各个简介之间样式和拼写统一")]),t._v(" "),s("li",[t._v("避免歧义（例如，如果有几个同名的城市）")]),t._v(" "),s("li",[t._v("易于更新——名称只存储在一个地方，如果需要更改（例如，由于政治事件而改变城市名称），很容易进行全面更新。")]),t._v(" "),s("li",[t._v("本地化支持——当网站翻译成其他语言时，标准化的列表可以被本地化，使得地区和行业可以使用用户的语言来显示")]),t._v(" "),s("li",[t._v("更好的搜索——例如，搜索华盛顿州的慈善家就会匹配这份简介，因为地区列表可以编码记录西雅图在华盛顿这一事实（从“Greater Seattle Area”这个字符串中看不出来）")])]),t._v(" "),s("p",[t._v("存储ID还是文本字符串，这是个 "),s("strong",[t._v("副本（duplication）")]),t._v(" 问题。当使用ID时，对人类有意义的信息（比如单词：Philanthropy）只存储在一处，所有引用它的地方使用ID（ID只在数据库中有意义）。当直接存储文本时，对人类有意义的信息会复制在每处使用记录中。")]),t._v(" "),s("p",[t._v("使用ID的好处是，ID对人类没有任何意义，因而永远不需要改变：ID可以保持不变，即使它标识的信息发生变化。任何对人类有意义的东西都可能需要在将来某个时候改变——如果这些信息被复制，所有的冗余副本都需要更新。这会导致写入开销，也存在不一致的风险（一些副本被更新了，还有些副本没有被更新）。去除此类重复是数据库 "),s("strong",[t._v("规范化（normalization）")]),t._v(" 的关键思想。"),s("a",{attrs:{href:"%E5%85%B3%E4%BA%8E%E5%85%B3%E7%B3%BB%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%96%87%E7%8C%AE%E5%8C%BA%E5%88%86%E4%BA%86%E5%87%A0%E7%A7%8D%E4%B8%8D%E5%90%8C%E7%9A%84%E8%A7%84%E8%8C%83%E5%BD%A2%E5%BC%8F%EF%BC%8C%E4%BD%86%E8%BF%99%E4%BA%9B%E5%8C%BA%E5%88%AB%E5%87%A0%E4%B9%8E%E6%B2%A1%E6%9C%89%E5%AE%9E%E9%99%85%E6%84%8F%E4%B9%89%E3%80%82%E4%B8%80%E4%B8%AA%E7%BB%8F%E9%AA%8C%E6%B3%95%E5%88%99%E6%98%AF%EF%BC%8C%E5%A6%82%E6%9E%9C%E9%87%8D%E5%A4%8D%E5%AD%98%E5%82%A8%E4%BA%86%E5%8F%AF%E4%BB%A5%E5%AD%98%E5%82%A8%E5%9C%A8%E4%B8%80%E4%B8%AA%E5%9C%B0%E6%96%B9%E7%9A%84%E5%80%BC%EF%BC%8C%E5%88%99%E6%A8%A1%E5%BC%8F%E5%B0%B1%E4%B8%8D%E6%98%AF**%E8%A7%84%E8%8C%83%E5%8C%96%EF%BC%88normalized%EF%BC%89**%E7%9A%84%E3%80%82"}},[t._v("^ii")])]),t._v(" "),s("blockquote",[s("p",[t._v("数据库管理员和开发人员喜欢争论规范化和非规范化，让我们暂时保留判断吧。在本书的"),s("RouterLink",{attrs:{to:"/ddia/part-iii.html"}},[t._v("第三部分")]),t._v("，我们将回到这个话题，探讨系统的方法用以处理缓存，非规范化和衍生数据。")],1)]),t._v(" "),s("p",[t._v("不幸的是，对这些数据进行规范化需要多对一的关系（许多人生活在一个特定的地区，许多人在一个特定的行业工作），这与文档模型不太吻合。在关系数据库中，通过ID来引用其他表中的行是正常的，因为连接很容易。在文档数据库中，一对多树结构没有必要用连接，对连接的支持通常很弱"),s("a",{attrs:{href:"%E5%9C%A8%E6%92%B0%E5%86%99%E6%9C%AC%E6%96%87%E6%97%B6%EF%BC%8CRethinkDB%E6%94%AF%E6%8C%81%E8%BF%9E%E6%8E%A5%EF%BC%8CMongoDB%E4%B8%8D%E6%94%AF%E6%8C%81%E8%BF%9E%E6%8E%A5%EF%BC%8C%E8%80%8CCouchDB%E5%8F%AA%E6%94%AF%E6%8C%81%E9%A2%84%E5%85%88%E5%A3%B0%E6%98%8E%E7%9A%84%E8%A7%86%E5%9B%BE%E3%80%82"}},[t._v("^iii")]),t._v("。")]),t._v(" "),s("p",[t._v("如果数据库本身不支持连接，则必须在应用程序代码中通过对数据库进行多个查询来模拟连接。（在这种情况中，地区和行业的列表可能很小，改动很少，应用程序可以简单地将其保存在内存中。不过，执行连接的工作从数据库被转移到应用程序代码上。")]),t._v(" "),s("p",[t._v("此外，即便应用程序的最初版本适合无连接的文档模型，随着功能添加到应用程序中，数据会变得更加互联。例如，考虑一下对简历例子进行的一些修改：")]),t._v(" "),s("p",[s("em",[s("strong",[t._v("组织和学校作为实体")])])]),t._v(" "),s("p",[t._v("在前面的描述中，"),s("code",[t._v("organization")]),t._v("（用户工作的公司）和"),s("code",[t._v("school_name")]),t._v("（他们学习的地方）只是字符串。也许他们应该是对实体的引用呢？然后，每个组织，学校或大学都可以拥有自己的网页（标识，新闻提要等）。每个简历可以链接到它所提到的组织和学校，并且包括他们的图标和其他信息（参见"),s("a",{attrs:{href:"img/fig2-3.png"}},[t._v("图2-3")]),t._v("，来自LinkedIn的一个例子）。")]),t._v(" "),s("p",[s("em",[s("strong",[t._v("推荐")])])]),t._v(" "),s("p",[t._v("假设你想添加一个新的功能：一个用户可以为另一个用户写一个推荐。在用户的简历上显示推荐，并附上推荐用户的姓名和照片。如果推荐人更新他们的照片，那他们写的任何建议都需要显示新的照片。因此，推荐应该拥有作者个人简介的引用。\n"),s("img",{attrs:{src:"img/fig2-3.png",alt:""}})]),t._v(" "),s("p",[s("strong",[t._v("图2-3 公司名不仅是字符串，还是一个指向公司实体的链接（LinkedIn截图）")])]),t._v(" "),s("p",[s("a",{attrs:{href:"img/fig2-4.png"}},[t._v("图2-4")]),t._v("阐明了这些新功能需要如何使用多对多关系。每个虚线矩形内的数据可以分组成一个文档，但是对单位，学校和其他用户的引用需要表示成引用，并且在查询时需要连接。")]),t._v(" "),s("p",[s("img",{attrs:{src:"img/fig2-4.png",alt:""}})]),t._v(" "),s("p",[s("strong",[t._v("图2-4 使用多对多关系扩展简历")])]),t._v(" "),s("h3",{attrs:{id:"文档数据库是否在重蹈覆辙？"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#文档数据库是否在重蹈覆辙？"}},[t._v("#")]),t._v(" 文档数据库是否在重蹈覆辙？")]),t._v(" "),s("p",[t._v("在多对多的关系和连接已常规用在关系数据库时，文档数据库和NoSQL重启了辩论：如何最好地在数据库中表示多对多关系。那场辩论可比NoSQL古老得多，事实上，最早可以追溯到计算机化数据库系统。")]),t._v(" "),s("p",[t._v("20世纪70年代最受欢迎的业务数据处理数据库是IBM的信息管理系统（IMS），最初是为了阿波罗太空计划的库存管理而开发的，并于1968年有了首次商业发布【13】。目前它仍在使用和维护，运行在IBM大型机的OS/390上【14】。")]),t._v(" "),s("p",[t._v("IMS的设计中使用了一个相当简单的数据模型，称为"),s("strong",[t._v("层次模型（hierarchical model）")]),t._v("，它与文档数据库使用的JSON模型有一些惊人的相似之处【2】。它将所有数据表示为嵌套在记录中的记录树，这很像"),s("a",{attrs:{href:"img/fig2-2.png"}},[t._v("图2-2")]),t._v("的JSON结构。")]),t._v(" "),s("p",[t._v("同文档数据库一样，IMS能良好处理一对多的关系，但是很难应对多对多的关系，并且不支持连接。开发人员必须决定是否复制（非规范化）数据或手动解决从一个记录到另一个记录的引用。这些二十世纪六七十年代的问题与现在开发人员遇到的文档数据库问题非常相似【15】。")]),t._v(" "),s("p",[t._v("那时人们提出了各种不同的解决方案来解决层次模型的局限性。其中最突出的两个是"),s("strong",[t._v("关系模型（relational model）")]),t._v("（它变成了SQL，统治了世界）和"),s("strong",[t._v("网络模型（network model）")]),t._v("（最初很受关注，但最终变得冷门）。这两个阵营之间的“大辩论”在70年代持续了很久时间【2】。")]),t._v(" "),s("p",[t._v("那两个模式解决的问题与当前的问题相关，因此值得简要回顾一下那场辩论。")]),t._v(" "),s("h4",{attrs:{id:"网络模型"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#网络模型"}},[t._v("#")]),t._v(" 网络模型")]),t._v(" "),s("p",[t._v("网络模型由一个称为数据系统语言会议（CODASYL）的委员会进行了标准化，并被数个不同的数据库商实现;它也被称为CODASYL模型【16】。")]),t._v(" "),s("p",[t._v("CODASYL模型是层次模型的推广。在层次模型的树结构中，每条记录只有一个父节点；在网络模式中，每条记录可能有多个父节点。例如，“Greater Seattle Area”地区可能是一条记录，每个居住在该地区的用户都可以与之相关联。这允许对多对一和多对多的关系进行建模。")]),t._v(" "),s("p",[t._v("网络模型中记录之间的链接不是外键，而更像编程语言中的指针（同时仍然存储在磁盘上）。访问记录的唯一方法是跟随从根记录起沿这些链路所形成的路径。这被称为"),s("strong",[t._v("访问路径（access path）")]),t._v("。")]),t._v(" "),s("p",[t._v("最简单的情况下，访问路径类似遍历链表：从列表头开始，每次查看一条记录，直到找到所需的记录。但在多对多关系的情况中，数条不同的路径可以到达相同的记录，网络模型的程序员必须跟踪这些不同的访问路径。")]),t._v(" "),s("p",[t._v("CODASYL中的查询是通过利用遍历记录列和跟随访问路径表在数据库中移动游标来执行的。如果记录有多个父结点（即多个来自其他记录的传入指针），则应用程序代码必须跟踪所有的各种关系。甚至CODASYL委员会成员也承认，这就像在n维数据空间中进行导航【17】。")]),t._v(" "),s("p",[t._v("尽管手动选择访问路径够能最有效地利用20世纪70年代非常有限的硬件功能（如磁带驱动器，其搜索速度非常慢），但这使得查询和更新数据库的代码变得复杂不灵活。无论是分层还是网络模型，如果你没有所需数据的路径，就会陷入困境。你可以改变访问路径，但是必须浏览大量手写数据库查询代码，并重写来处理新的访问路径。更改应用程序的数据模型是很难的。")]),t._v(" "),s("h4",{attrs:{id:"关系模型"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#关系模型"}},[t._v("#")]),t._v(" 关系模型")]),t._v(" "),s("p",[t._v("相比之下，关系模型做的就是将所有的数据放在光天化日之下：一个 "),s("strong",[t._v("关系（表）")]),t._v(" 只是一个 "),s("strong",[t._v("元组（行）")]),t._v(" 的集合，仅此而已。如果你想读取数据，它没有迷宫似的嵌套结构，也没有复杂的访问路径。你可以选中符合任意条件的行，读取表中的任何或所有行。你可以通过指定某些列作为匹配关键字来读取特定行。你可以在任何表中插入一个新的行，而不必担心与其他表的外键关系"),s("a",{attrs:{href:"%E5%A4%96%E9%94%AE%E7%BA%A6%E6%9D%9F%E5%85%81%E8%AE%B8%E5%AF%B9%E4%BF%AE%E6%94%B9%E7%BA%A6%E6%9D%9F%EF%BC%8C%E4%BD%86%E5%AF%B9%E4%BA%8E%E5%85%B3%E7%B3%BB%E6%A8%A1%E5%9E%8B%E8%BF%99%E5%B9%B6%E4%B8%8D%E6%98%AF%E5%BF%85%E9%80%89%E9%A1%B9%E3%80%82%E5%8D%B3%E4%BD%BF%E6%9C%89%E7%BA%A6%E6%9D%9F%EF%BC%8C%E5%A4%96%E9%94%AE%E8%BF%9E%E6%8E%A5%E5%9C%A8%E6%9F%A5%E8%AF%A2%E6%97%B6%E6%89%A7%E8%A1%8C%EF%BC%8C%E8%80%8C%E5%9C%A8CODASYL%E4%B8%AD%EF%BC%8C%E8%BF%9E%E6%8E%A5%E5%9C%A8%E6%8F%92%E5%85%A5%E6%97%B6%E9%AB%98%E6%95%88%E5%AE%8C%E6%88%90%E3%80%82"}},[t._v("^iv")]),t._v("。")]),t._v(" "),s("p",[t._v("在关系数据库中，查询优化器自动决定查询的哪些部分以哪个顺序执行，以及使用哪些索引。这些选择实际上是“访问路径”，但最大的区别在于它们是由查询优化器自动生成的，而不是由程序员生成，所以我们很少需要考虑它们。")]),t._v(" "),s("p",[t._v("如果想按新的方式查询数据，你可以声明一个新的索引，查询会自动使用最合适的那些索引。无需更改查询来利用新的索引。（请参阅“"),s("a",{attrs:{href:"#%E7%94%A8%E4%BA%8E%E6%95%B0%E6%8D%AE%E7%9A%84%E6%9F%A5%E8%AF%A2%E8%AF%AD%E8%A8%80"}},[t._v("用于数据的查询语言")]),t._v("”。）关系模型因此使添加应用程序新功能变得更加容易。")]),t._v(" "),s("p",[t._v("关系数据库的查询优化器是复杂的，已耗费了多年的研究和开发精力【18】。关系模型的一个关键洞察是：只需构建一次查询优化器，随后使用该数据库的所有应用程序都可以从中受益。如果你没有查询优化器的话，那么为特定查询手动编写访问路径比编写通用优化器更容易——不过从长期看通用解决方案更好。")]),t._v(" "),s("h4",{attrs:{id:"与文档数据库相比"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#与文档数据库相比"}},[t._v("#")]),t._v(" 与文档数据库相比")]),t._v(" "),s("p",[t._v("在一个方面，文档数据库还原为层次模型：在其父记录中存储嵌套记录（"),s("a",{attrs:{href:""}},[t._v("图2-1")]),t._v("中的一对多关系，如"),s("code",[t._v("positions")]),t._v("，"),s("code",[t._v("education")]),t._v("和"),s("code",[t._v("contact_info")]),t._v("），而不是在单独的表中。")]),t._v(" "),s("p",[t._v("但是，在表示多对一和多对多的关系时，关系数据库和文档数据库并没有根本的不同：在这两种情况下，相关项目都被一个唯一的标识符引用，这个标识符在关系模型中被称为"),s("strong",[t._v("外键")]),t._v("，在文档模型中称为"),s("strong",[t._v("文档引用")]),t._v("【9】。该标识符在读取时通过连接或后续查询来解析。迄今为止，文档数据库没有走CODASYL的老路。")]),t._v(" "),s("h3",{attrs:{id:"关系型数据库与文档数据库在今日的对比"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#关系型数据库与文档数据库在今日的对比"}},[t._v("#")]),t._v(" 关系型数据库与文档数据库在今日的对比")]),t._v(" "),s("p",[t._v("将关系数据库与文档数据库进行比较时，可以考虑许多方面的差异，包括它们的容错属性（参阅"),s("RouterLink",{attrs:{to:"/ddia/ch5.html"}},[t._v("第5章")]),t._v("）和处理并发性（参阅"),s("RouterLink",{attrs:{to:"/ddia/ch7.html"}},[t._v("第7章")]),t._v("）。本章将只关注数据模型中的差异。")],1),t._v(" "),s("p",[t._v("支持文档数据模型的主要论据是架构灵活性，因局部性而拥有更好的性能，以及对于某些应用程序而言更接近于应用程序使用的数据结构。关系模型通过为连接提供更好的支持以及支持多对一和多对多的关系来反击。")]),t._v(" "),s("h4",{attrs:{id:"哪个数据模型更方便写代码？"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#哪个数据模型更方便写代码？"}},[t._v("#")]),t._v(" 哪个数据模型更方便写代码？")]),t._v(" "),s("p",[t._v("如果应用程序中的数据具有类似文档的结构（即，一对多关系树，通常一次性加载整个树），那么使用文档模型可能是一个好主意。将类似文档的结构分解成多个表（如"),s("a",{attrs:{href:"img/fig2-1.png"}},[t._v("图2-1")]),t._v("中的"),s("code",[t._v("positions")]),t._v("，"),s("code",[t._v("education")]),t._v("和"),s("code",[t._v("contact_info")]),t._v("）的关系技术可能导致繁琐的模式和不必要的复杂的应用程序代码。")]),t._v(" "),s("p",[t._v("文档模型有一定的局限性：例如，不能直接引用文档中的嵌套的项目，而是需要说“用户251的位置列表中的第二项”（很像分层模型中的访问路径）。但是，只要文件嵌套不太深，这通常不是问题。")]),t._v(" "),s("p",[t._v("文档数据库对连接的糟糕支持也许或也许不是一个问题，这取决于应用程序。例如，分析应用程可能永远不需要多对多的关系，如果它使用文档数据库来记录何事发生于何时【19】。")]),t._v(" "),s("p",[t._v("但是，如果你的应用程序确实使用多对多关系，那么文档模型就没有那么吸引人了。通过反规范化可以减少对连接的需求，但是应用程序代码需要做额外的工作来保持数据的一致性。通过向数据库发出多个请求，可以在应用程序代码中模拟连接，但是这也将复杂性转移到应用程序中，并且通常比由数据库内的专用代码执行的连接慢。在这种情况下，使用文档模型会导致更复杂的应用程序代码和更差的性能【15】。")]),t._v(" "),s("p",[t._v("很难说在一般情况下哪个数据模型让应用程序代码更简单；它取决于数据项之间存在的关系种类。对于高度相联的数据，选用文档模型是糟糕的，选用关系模型是可接受的，而选用图形模型（参见“"),s("a",{attrs:{href:"#%E5%9B%BE%E6%95%B0%E6%8D%AE%E6%A8%A1%E5%9E%8B"}},[t._v("图数据模型")]),t._v("”）是最自然的。")]),t._v(" "),s("h4",{attrs:{id:"文档模型中的架构灵活性"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#文档模型中的架构灵活性"}},[t._v("#")]),t._v(" 文档模型中的架构灵活性")]),t._v(" "),s("p",[t._v("大多数文档数据库以及关系数据库中的JSON支持都不会强制文档中的数据采用何种模式。关系数据库的XML支持通常带有可选的模式验证。没有模式意味着可以将任意的键和值添加到文档中，并且当读取时，客户端对无法保证文档可能包含的字段。")]),t._v(" "),s("p",[t._v("文档数据库有时称为"),s("strong",[t._v("无模式（schemaless）")]),t._v("，但这具有误导性，因为读取数据的代码通常假定某种结构——即存在隐式模式，但不由数据库强制执行【20】。一个更精确的术语是"),s("strong",[t._v("读时模式（schema-on-read）")]),t._v("（数据的结构是隐含的，只有在数据被读取时才被解释），相应的是"),s("strong",[t._v("写时模式（schema-on-write）")]),t._v("（传统的关系数据库方法中，模式明确，且数据库确保所有的数据都符合其模式）【21】。")]),t._v(" "),s("p",[t._v("读时模式类似于编程语言中的动态（运行时）类型检查，而写时模式类似于静态（编译时）类型检查。就像静态和动态类型检查的相对优点具有很大的争议性一样【22】，数据库中模式的强制性是一个具有争议的话题，一般来说没有正确或错误的答案。")]),t._v(" "),s("p",[t._v("在应用程序想要改变其数据格式的情况下，这些方法之间的区别尤其明显。例如，假设你把每个用户的全名存储在一个字段中，而现在想分别存储名字和姓氏【23】。在文档数据库中，只需开始写入具有新字段的新文档，并在应用程序中使用代码来处理读取旧文档的情况。例如：")]),t._v(" "),s("div",{staticClass:"language-go extra-class"},[s("pre",{pre:!0,attrs:{class:"language-go"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("user "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&&")]),t._v(" user"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("name "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&&")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!")]),t._v("user"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("first_name"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n\t"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// Documents written before Dec 8, 2013 don't have first_name")]),t._v("\n\tuser"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("first_name "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" user"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("name"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("split")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('" "')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),s("p",[t._v("另一方面，在“静态类型”数据库模式中，通常会执行以下 "),s("strong",[t._v("迁移（migration）")]),t._v(" 操作：")]),t._v(" "),s("div",{staticClass:"language-sql extra-class"},[s("pre",{pre:!0,attrs:{class:"language-sql"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("ALTER")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("TABLE")]),t._v(" users "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("ADD")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("COLUMN")]),t._v(" first_name "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("text")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("UPDATE")]),t._v(" users "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("SET")]),t._v(" first_name "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" split_part"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("name"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("' '")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" \t\t"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("-- PostgreSQL")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("UPDATE")]),t._v(" users "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("SET")]),t._v(" first_name "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" substring_index"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("name"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("' '")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" \t"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("-- MySQL")]),t._v("\n")])])]),s("p",[t._v("模式变更的速度很慢，而且要求停运。它的这种坏名誉并不是完全应得的：大多数关系数据库系统可在几毫秒内执行"),s("code",[t._v("ALTER TABLE")]),t._v("语句。MySQL是一个值得注意的例外，它执行"),s("code",[t._v("ALTER TABLE")]),t._v("时会复制整个表，这可能意味着在更改一个大型表时会花费几分钟甚至几个小时的停机时间，尽管存在各种工具来解决这个限制【24,25,26】。")]),t._v(" "),s("p",[t._v("大型表上运行"),s("code",[t._v("UPDATE")]),t._v("语句在任何数据库上都可能会很慢，因为每一行都需要重写。要是不可接受的话，应用程序可以将"),s("code",[t._v("first_name")]),t._v("设置为默认值"),s("code",[t._v("NULL")]),t._v("，并在读取时再填充，就像使用文档数据库一样。")]),t._v(" "),s("p",[t._v("当由于某种原因（例如，数据是异构的）集合中的项目并不都具有相同的结构时,读时模式更具优势。例如，如果：")]),t._v(" "),s("ul",[s("li",[t._v("存在许多不同类型的对象，将每种类型的对象放在自己的表中是不现实的。")]),t._v(" "),s("li",[t._v("数据的结构由外部系统决定。你无法控制外部系统且它随时可能变化。")])]),t._v(" "),s("p",[t._v("在上述情况下，模式的坏处远大于它的帮助，无模式文档可能是一个更加自然的数据模型。但是，要是所有记录都具有相同的结构，那么模式是记录并强制这种结构的有效机制。第四章将更详细地讨论模式和模式演化。")]),t._v(" "),s("h4",{attrs:{id:"查询的数据局部性"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#查询的数据局部性"}},[t._v("#")]),t._v(" 查询的数据局部性")]),t._v(" "),s("p",[t._v("文档通常以单个连续字符串形式进行存储，编码为JSON，XML或其二进制变体（如MongoDB的BSON）。如果应用程序经常需要访问整个文档（例如，将其渲染至网页），那么存储局部性会带来性能优势。如果将数据分割到多个表中（如"),s("a",{attrs:{href:"img/fig2-1.png"}},[t._v("图2-1")]),t._v("所示），则需要进行多次索引查找才能将其全部检索出来，这可能需要更多的磁盘查找并花费更多的时间。")]),t._v(" "),s("p",[t._v("局部性仅仅适用于同时需要文档绝大部分内容的情况。数据库通常需要加载整个文档，即使只访问其中的一小部分，这对于大型文档来说是很浪费的。更新文档时，通常需要整个重写。只有不改变文档大小的修改才可以容易地原地执行。因此，通常建议保持相对小的文档，并避免增加文档大小的写入【9】。这些性能限制大大减少了文档数据库的实用场景。")]),t._v(" "),s("p",[t._v("值得指出的是，为了局部性而分组集合相关数据的想法并不局限于文档模型。例如，Google的Spanner数据库在关系数据模型中提供了同样的局部性属性，允许模式声明一个表的行应该交错（嵌套）在父表内【27】。Oracle类似地允许使用一个称为 "),s("strong",[t._v("多表索引集群表（multi-table index cluster tables）")]),t._v(" 的类似特性【28】。Bigtable数据模型（用于Cassandra和HBase）中的 "),s("strong",[t._v("列族（column-family）")]),t._v(" 概念与管理局部性的目的类似【29】。")]),t._v(" "),s("p",[t._v("在"),s("RouterLink",{attrs:{to:"/ddia/ch3.html"}},[t._v("第3章")]),t._v("将还会看到更多关于局部性的内容。")],1),t._v(" "),s("h4",{attrs:{id:"文档和关系数据库的融合"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#文档和关系数据库的融合"}},[t._v("#")]),t._v(" 文档和关系数据库的融合")]),t._v(" "),s("p",[t._v("自2000年代中期以来，大多数关系数据库系统（MySQL除外）都已支持XML。这包括对XML文档进行本地修改的功能，以及在XML文档中进行索引和查询的功能。这允许应用程序使用那种与文档数据库应当使用的非常类似的数据模型。")]),t._v(" "),s("p",[t._v("从9.3版本开始的PostgreSQL 【8】，从5.7版本开始的MySQL以及从版本10.5开始的IBM DB2 [30]也对JSON文档提供了类似的支持级别。鉴于用在Web APIs的JSON流行趋势，其他关系数据库很可能会跟随他们的脚步并添加JSON支持。")]),t._v(" "),s("p",[t._v("在文档数据库中，RethinkDB在其查询语言中支持类似关系的连接，一些MongoDB驱动程序可以自动解析数据库引用（有效地执行客户端连接，尽管这可能比在数据库中执行的连接慢，需要额外的网络往返，并且优化更少）。")]),t._v(" "),s("p",[t._v("随着时间的推移，关系数据库和文档数据库似乎变得越来越相似，这是一件好事：数据模型相互补充[^v]，如果一个数据库能够处理类似文档的数据，并能够对其执行关系查询，那么应用程序就可以使用最符合其需求的功能组合。")]),t._v(" "),s("p",[t._v("关系模型和文档模型的混合是未来数据库一条很好的路线。")]),t._v(" "),s("p",[t._v("[^v]: Codd对关系模型【1】的原始描述实际上允许在关系模式中与JSON文档非常相似。他称之为"),s("strong",[t._v("非简单域（nonsimple domains）")]),t._v("。这个想法是，一行中的值不一定是一个像数字或字符串一样的原始数据类型，也可以是一个嵌套的关系（表），因此可以把一个任意嵌套的树结构作为一个值，这很像30年后添加到SQL中的JSON或XML支持。")]),t._v(" "),s("h2",{attrs:{id:"数据查询语言"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#数据查询语言"}},[t._v("#")]),t._v(" 数据查询语言")]),t._v(" "),s("p",[t._v("当引入关系模型时，关系模型包含了一种查询数据的新方法：SQL是一种 "),s("strong",[t._v("声明式")]),t._v(" 查询语言，而IMS和CODASYL使用 "),s("strong",[t._v("命令式")]),t._v(" 代码来查询数据库。那是什么意思？")]),t._v(" "),s("p",[t._v("许多常用的编程语言是命令式的。例如，给定一个动物物种的列表，返回列表中的鲨鱼可以这样写：")]),t._v(" "),s("div",{staticClass:"language-js extra-class"},[s("pre",{pre:!0,attrs:{class:"language-js"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("getSharks")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("var")]),t._v(" sharks "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("var")]),t._v(" i "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" i "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v(" animals"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("length"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" i"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("++")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("animals"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("i"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("family "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("===")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Sharks"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n            sharks"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("push")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("animals"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("i"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" sharks"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),s("p",[t._v('在关系代数中：\n$$\nsharks = σ_{family = "sharks"}(animals)\n$$\nσ（希腊字母西格玛）是选择操作符，只返回符合条件的动物，'),s("code",[t._v('family="shark"')]),t._v("。")]),t._v(" "),s("p",[t._v("定义SQL时，它紧密地遵循关系代数的结构：")]),t._v(" "),s("div",{staticClass:"language-sql extra-class"},[s("pre",{pre:!0,attrs:{class:"language-sql"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("SELECT")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("FROM")]),t._v(" animals "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("WHERE")]),t._v(" family "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Sharks'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),s("p",[t._v("命令式语言告诉计算机以特定顺序执行某些操作。可以想象一下，逐行地遍历代码，评估条件，更新变量，并决定是否再循环一遍。")]),t._v(" "),s("p",[t._v("在声明式查询语言（如SQL或关系代数）中，你只需指定所需数据的模式 - 结果必须符合哪些条件，以及如何将数据转换（例如，排序，分组和集合） - 但不是如何实现这一目标。数据库系统的查询优化器决定使用哪些索引和哪些连接方法，以及以何种顺序执行查询的各个部分。")]),t._v(" "),s("p",[t._v("声明式查询语言是迷人的，因为它通常比命令式API更加简洁和容易。但更重要的是，它还隐藏了数据库引擎的实现细节，这使得数据库系统可以在无需对查询做任何更改的情况下进行性能提升。")]),t._v(" "),s("p",[t._v("例如，在本节开头所示的命令代码中，动物列表以特定顺序出现。如果数据库想要在后台回收未使用的磁盘空间，则可能需要移动记录，这会改变动物出现的顺序。数据库能否安全地执行，而不会中断查询？")]),t._v(" "),s("p",[t._v("SQL示例不确保任何特定的顺序，因此不在意顺序是否改变。但是如果查询用命令式的代码来写的话，那么数据库就永远不可能确定代码是否依赖于排序。SQL相当有限的功能性为数据库提供了更多自动优化的空间。")]),t._v(" "),s("p",[t._v("最后，声明式语言往往适合并行执行。现在，CPU的速度通过内核的增加变得更快，而不是以比以前更高的时钟速度运行【31】。命令代码很难在多个内核和多个机器之间并行化，因为它指定了指令必须以特定顺序执行。声明式语言更具有并行执行的潜力，因为它们仅指定结果的模式，而不指定用于确定结果的算法。在适当情况下，数据库可以自由使用查询语言的并行实现【32】。")]),t._v(" "),s("h3",{attrs:{id:"web上的声明式查询"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#web上的声明式查询"}},[t._v("#")]),t._v(" Web上的声明式查询")]),t._v(" "),s("p",[t._v("声明式查询语言的优势不仅限于数据库。为了说明这一点，让我们在一个完全不同的环境中比较声明式和命令式方法：一个Web浏览器。")]),t._v(" "),s("p",[t._v("假设你有一个关于海洋动物的网站。用户当前正在查看鲨鱼页面，因此你将当前所选的导航项目“鲨鱼”标记为当前选中项目。")]),t._v(" "),s("div",{staticClass:"language-html extra-class"},[s("pre",{pre:!0,attrs:{class:"language-html"}},[s("code",[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("ul")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("li")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("class")]),s("span",{pre:!0,attrs:{class:"token attr-value"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')]),t._v("selected"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')])]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("p")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("Sharks"),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("p")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("ul")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("li")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("Great White Shark"),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("li")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("li")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("Tiger Shark"),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("li")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("li")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("Hammerhead Shark"),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("li")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("ul")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("li")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("li")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("p")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("Whales"),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("p")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("ul")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("li")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("Blue Whale"),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("li")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("li")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("Humpback Whale"),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("li")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("li")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("Fin Whale"),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("li")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("ul")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("li")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("ul")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n")])])]),s("p",[t._v("现在想让当前所选页面的标题具有一个蓝色的背景，以便在视觉上突出显示。使用CSS实现起来非常简单：")]),t._v(" "),s("div",{staticClass:"language-css extra-class"},[s("pre",{pre:!0,attrs:{class:"language-css"}},[s("code",[s("span",{pre:!0,attrs:{class:"token selector"}},[t._v("li.selected > p")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n\t"),s("span",{pre:!0,attrs:{class:"token property"}},[t._v("background-color")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" blue"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),s("p",[t._v("这里的CSS选择器"),s("code",[t._v("li.selected> p")]),t._v("声明了我们想要应用蓝色样式的元素的模式：即其直接父元素是具有"),s("code",[t._v("selected")]),t._v("CSS类的"),s("code",[t._v("<li>")]),t._v("元素的所有"),s("code",[t._v("<p>")]),t._v("元素。示例中的元素"),s("code",[t._v("<p> Sharks </p>")]),t._v("匹配此模式，但"),s("code",[t._v("<p> Whales </p>")]),t._v("不匹配，因为其"),s("code",[t._v("<li>")]),t._v("父元素缺少"),s("code",[t._v("class =“selected”")]),t._v("。")]),t._v(" "),s("p",[t._v("如果使用XSL而不是CSS，你可以做类似的事情：")]),t._v(" "),s("div",{staticClass:"language-xml extra-class"},[s("pre",{pre:!0,attrs:{class:"language-xml"}},[s("code",[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("xsl:")]),t._v("template")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("match")]),s("span",{pre:!0,attrs:{class:"token attr-value"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')]),t._v("li[@class='selected']/p"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')])]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("fo:")]),t._v("block")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("background-color")]),s("span",{pre:!0,attrs:{class:"token attr-value"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')]),t._v("blue"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')])]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("xsl:")]),t._v("apply-templates")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("/>")])]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),s("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("fo:")]),t._v("block")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),s("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("xsl:")]),t._v("template")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n")])])]),s("p",[t._v("这里的XPath表达式"),s("code",[t._v("li[@class='selected']/p")]),t._v("相当于上例中的CSS选择器"),s("code",[t._v("li.selected> p")]),t._v("。CSS和XSL的共同之处在于，它们都是用于指定文档样式的声明式语言。")]),t._v(" "),s("p",[t._v("想象一下，必须使用命令式方法的情况会是如何。在Javascript中，使用 "),s("strong",[t._v("文档对象模型（DOM）")]),t._v(" API，其结果可能如下所示：")]),t._v(" "),s("div",{staticClass:"language-js extra-class"},[s("pre",{pre:!0,attrs:{class:"language-js"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("var")]),t._v(" liElements "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" document"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("getElementsByTagName")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"li"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("var")]),t._v(" i "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" i "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v(" liElements"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("length"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" i"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("++")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("liElements"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("i"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("className "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("===")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"selected"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("var")]),t._v(" children "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" liElements"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("i"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("childNodes"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("var")]),t._v(" j "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" j "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v(" children"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("length"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" j"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("++")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("var")]),t._v(" child "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" children"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("j"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("child"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nodeType "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("===")]),t._v(" Node"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token constant"}},[t._v("ELEMENT_NODE")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&&")]),t._v(" child"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("tagName "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("===")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"P"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n                child"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("setAttribute")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"style"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"background-color: blue"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),s("p",[t._v("这段JavaScript代码命令式地将元素设置为蓝色背景，但是代码看起来很糟糕。不仅比CSS和XSL等价物更长，更难理解，而且还有一些严重的问题：")]),t._v(" "),s("ul",[s("li",[s("p",[t._v("如果选定的类被移除（例如，因为用户点击了不同的页面），即使代码重新运行，蓝色背景也不会被移除 - 因此该项目将保持突出显示，直到整个页面被重新加载。使用CSS，浏览器会自动检测"),s("code",[t._v("li.selected> p")]),t._v("规则何时不再适用，并在选定的类被移除后立即移除蓝色背景。")])]),t._v(" "),s("li",[s("p",[t._v("如果你想要利用新的API（例如"),s("code",[t._v("document.getElementsBy ClassName（“selected”")]),t._v("）甚至"),s("code",[t._v("document.evaluate()")]),t._v("）来提高性能，则必须重写代码。另一方面，浏览器供应商可以在不破坏兼容性的情况下提高CSS和XPath的性能。")])])]),t._v(" "),s("p",[t._v("在Web浏览器中，使用声明式CSS样式比使用JavaScript命令式地操作样式要好得多。类似地，在数据库中，使用像SQL这样的声明式查询语言比使用命令式查询API要好得多"),s("a",{attrs:{href:"vi%C2%A0IMS%E5%92%8CCODASYL%E9%83%BD%E4%BD%BF%E7%94%A8%E5%91%BD%E4%BB%A4%E5%BC%8FAPI%E3%80%82%E5%BA%94%E7%94%A8%E7%A8%8B%E5%BA%8F%E9%80%9A%E5%B8%B8%E4%BD%BF%E7%94%A8COBOL%E4%BB%A3%E7%A0%81%E9%81%8D%E5%8E%86%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%AD%E7%9A%84%E8%AE%B0%E5%BD%95%EF%BC%8C%E4%B8%80%E6%AC%A1%E4%B8%80%E6%9D%A1%E8%AE%B0%E5%BD%95%E3%80%902,16%E3%80%91%E3%80%82"}},[t._v("^vi")]),t._v("。")]),t._v(" "),s("h3",{attrs:{id:"mapreduce查询"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#mapreduce查询"}},[t._v("#")]),t._v(" MapReduce查询")]),t._v(" "),s("p",[t._v("MapReduce是一个由Google推广的编程模型，用于在多台机器上批量处理大规模的数据【33】。一些NoSQL数据存储（包括MongoDB和CouchDB）支持有限形式的MapReduce，作为在多个文档中执行只读查询的机制。")]),t._v(" "),s("p",[t._v("MapReduce将"),s("RouterLink",{attrs:{to:"/ddia/ch10.html"}},[t._v("第10章")]),t._v("中有更详细的描述。现在我们将简要讨论一下MongoDB使用的模型。")],1),t._v(" "),s("p",[t._v("MapReduce既不是一个声明式的查询语言，也不是一个完全命令式的查询API，而是处于两者之间：查询的逻辑用代码片断来表示，这些代码片段会被处理框架重复性调用。它基于"),s("code",[t._v("map")]),t._v("（也称为"),s("code",[t._v("collect")]),t._v("）和"),s("code",[t._v("reduce")]),t._v("（也称为"),s("code",[t._v("fold")]),t._v("或"),s("code",[t._v("inject")]),t._v("）函数，两个函数存在于许多函数式编程语言中。")]),t._v(" "),s("p",[t._v("最好举例来解释MapReduce模型。假设你是一名海洋生物学家，每当你看到海洋中的动物时，你都会在数据库中添加一条观察记录。现在你想生成一个报告，说明你每月看到多少鲨鱼。")]),t._v(" "),s("p",[t._v("在PostgreSQL中，你可以像这样表述这个查询：")]),t._v(" "),s("div",{staticClass:"language-sql extra-class"},[s("pre",{pre:!0,attrs:{class:"language-sql"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("SELECT")]),t._v("\n\tdate_trunc"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'month'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" observation_timestamp"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("AS")]),t._v(" observation_month"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n\t"),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("sum")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("num_animals"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("                           "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("AS")]),t._v(" total_animals\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("FROM")]),t._v(" observations\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("WHERE")]),t._v(" family "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Sharks'")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("GROUP")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("BY")]),t._v(" observation_month"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),s("p",[s("code",[t._v("date_trunc('month'，timestamp)")]),t._v("函数用于确定包含"),s("code",[t._v("timestamp")]),t._v("的日历月份，并返回代表该月份开始的另一个时间戳。换句话说，它将时间戳舍入成最近的月份。")]),t._v(" "),s("p",[t._v("这个查询首先过滤观察记录，以只显示鲨鱼家族的物种，然后根据它们发生的日历月份对观察记录果进行分组，最后将在该月的所有观察记录中看到的动物数目加起来。")]),t._v(" "),s("p",[t._v("同样的查询用MongoDB的MapReduce功能可以按如下来表述：")]),t._v(" "),s("div",{staticClass:"language-js extra-class"},[s("pre",{pre:!0,attrs:{class:"language-js"}},[s("code",[t._v("db"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("observations"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("mapReduce")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("map")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("var")]),t._v(" year "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("this")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("observationTimestamp"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("getFullYear")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("var")]),t._v(" month "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("this")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("observationTimestamp"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("getMonth")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("emit")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("year "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"-"')]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" month"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("this")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("numAnimals"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("reduce")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token parameter"}},[t._v("key"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" values")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" Array"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("sum")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("values"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        query"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n          family"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Sharks"')]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        out"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"monthlySharkReport"')]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),s("ul",[s("li",[t._v("可以声明式地指定只考虑鲨鱼种类的过滤器（这是一个针对MapReduce的特定于MongoDB的扩展）。")]),t._v(" "),s("li",[t._v("每个匹配查询的文档都会调用一次JavaScript函数"),s("code",[t._v("map")]),t._v("，将"),s("code",[t._v("this")]),t._v("设置为文档对象。")]),t._v(" "),s("li",[s("code",[t._v("map")]),t._v("函数发出一个键（包括年份和月份的字符串，如"),s("code",[t._v('"2013-12"')]),t._v("或"),s("code",[t._v('"2014-1"')]),t._v("）和一个值（该观察记录中的动物数量）。")]),t._v(" "),s("li",[s("code",[t._v("map")]),t._v("发出的键值对按键来分组。对于具有相同键（即，相同的月份和年份）的所有键值对，调用一次"),s("code",[t._v("reduce")]),t._v("函数。")]),t._v(" "),s("li",[s("code",[t._v("reduce")]),t._v("函数将特定月份内所有观测记录中的动物数量相加。")]),t._v(" "),s("li",[t._v("将最终的输出写入到"),s("code",[t._v("monthlySharkReport")]),t._v("集合中。")])]),t._v(" "),s("p",[t._v("例如，假设"),s("code",[t._v("observations")]),t._v("集合包含这两个文档：")]),t._v(" "),s("div",{staticClass:"language-json extra-class"},[s("pre",{pre:!0,attrs:{class:"language-json"}},[s("code",[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  observationTimestamp"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Date.parse(  "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Mon, 25 Dec 1995 12:34:56 GMT"')]),t._v(")"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  family"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Sharks"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  species"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Carcharodon carcharias"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  numAnimals"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n  observationTimestamp"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Date.parse("),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Tue, 12 Dec 1995 16:17:18 GMT"')]),t._v(")"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  family"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Sharks"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  species"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v("    "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Carcharias taurus"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  numAnimals"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),s("p",[t._v("对每个文档都会调用一次"),s("code",[t._v("map")]),t._v("函数，结果将是"),s("code",[t._v('emit("1995-12",3)')]),t._v("和"),s("code",[t._v('emit("1995-12",4)')]),t._v("。随后，以"),s("code",[t._v('reduce("1995-12",[3,4])')]),t._v("调用"),s("code",[t._v("reduce")]),t._v("函数，将返回"),s("code",[t._v("7")]),t._v("。")]),t._v(" "),s("p",[t._v("map和reduce函数在功能上有所限制：它们必须是"),s("strong",[t._v("纯")]),t._v("函数，这意味着它们只使用传递给它们的数据作为输入，它们不能执行额外的数据库查询，也不能有任何副作用。这些限制允许数据库以任何顺序运行任何功能，并在失败时重新运行它们。然而，map和reduce函数仍然是强大的：它们可以解析字符串，调用库函数，执行计算等等。")]),t._v(" "),s("p",[t._v("MapReduce是一个相当底层的编程模型，用于计算机集群上的分布式执行。像SQL这样的更高级的查询语言可以用一系列的MapReduce操作来实现（见"),s("RouterLink",{attrs:{to:"/ddia/ch10.html"}},[t._v("第10章")]),t._v("），但是也有很多不使用MapReduce的分布式SQL实现。请注意，SQL中没有任何内容限制它在单个机器上运行，而MapReduce在分布式查询执行上没有垄断权。")],1),t._v(" "),s("p",[t._v("能够在查询中使用JavaScript代码是高级查询的一个重要特性，但这不限于MapReduce，一些SQL数据库也可以用JavaScript函数进行扩展【34】。")]),t._v(" "),s("p",[t._v("MapReduce的一个可用性问题是，必须编写两个密切合作的JavaScript函数，这通常比编写单个查询更困难。此外，声明式查询语言为查询优化器提供了更多机会来提高查询的性能。基于这些原因，MongoDB 2.2添加了一种叫做"),s("strong",[t._v("聚合管道")]),t._v("的声明式查询语言的支持【9】。用这种语言表述鲨鱼计数查询如下所示：")]),t._v(" "),s("div",{staticClass:"language-js extra-class"},[s("pre",{pre:!0,attrs:{class:"language-js"}},[s("code",[t._v("db"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("observations"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("aggregate")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" $match"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" family"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Sharks"')]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" $group"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    _id"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      year"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" $year"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"$observationTimestamp"')]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      month"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" $month"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"$observationTimestamp"')]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    totalAnimals"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" $sum"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"$numAnimals"')]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),s("p",[t._v("聚合管道语言与SQL的子集具有类似表现力，但是它使用基于JSON的语法而不是SQL的英语句子式语法; 这种差异也许是口味问题。这个故事的寓意是NoSQL系统可能会发现自己意外地重新发明了SQL，尽管带着伪装。")]),t._v(" "),s("h2",{attrs:{id:"图数据模型"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#图数据模型"}},[t._v("#")]),t._v(" 图数据模型")]),t._v(" "),s("p",[t._v("如我们之前所见，多对多关系是不同数据模型之间具有区别性的重要特征。如果你的应用程序大多数的关系是一对多关系（树状结构化数据），或者大多数记录之间不存在关系，那么使用文档模型是合适的。")]),t._v(" "),s("p",[t._v("但是，要是多对多关系在你的数据中很常见呢？关系模型可以处理多对多关系的简单情况，但是随着数据之间的连接变得更加复杂，将数据建模为图形显得更加自然。")]),t._v(" "),s("p",[t._v("一个图由两种对象组成："),s("strong",[t._v("顶点（vertices）")]),t._v("（也称为"),s("strong",[t._v("节点（nodes）")]),t._v(" 或"),s("strong",[t._v("实体（entities）")]),t._v("），和"),s("strong",[t._v("边（edges）")]),t._v("（ 也称为"),s("strong",[t._v("关系（relationships）"),s("strong",[t._v("或")]),t._v("弧 （arcs）")]),t._v(" ）。多种数据可以被建模为一个图形。典型的例子包括：")]),t._v(" "),s("p",[s("em",[s("strong",[t._v("社交图谱")])])]),t._v(" "),s("p",[t._v("顶点是人，边指示哪些人彼此认识。")]),t._v(" "),s("p",[s("em",[s("strong",[t._v("网络图谱")])])]),t._v(" "),s("p",[t._v("顶点是网页，边缘表示指向其他页面的HTML链接。")]),t._v(" "),s("p",[s("em",[s("strong",[t._v("公路或铁路网络")])])]),t._v(" "),s("p",[t._v("顶点是交叉路口，边线代表它们之间的道路或铁路线。")]),t._v(" "),s("p",[t._v("可以将那些众所周知的算法运用到这些图上：例如，汽车导航系统搜索道路网络中两点之间的最短路径，PageRank可以用在网络图上来确定网页的流行程度，从而确定该网页在搜索结果中的排名。")]),t._v(" "),s("p",[t._v("在刚刚给出的例子中，图中的所有顶点代表了相同类型的事物（人，网页或交叉路口）。不过，图并不局限于这样的同类数据：同样强大地是，图提供了一种一致的方式，用来在单个数据存储中存储完全不同类型的对象。例如，Facebook维护一个包含许多不同类型的顶点和边的单个图：顶点表示人，地点，事件，签到和用户的评论;边缘表示哪些人是彼此的朋友，哪个签到发生在何处，谁评论了哪条消息，谁参与了哪个事件，等等【35】。")]),t._v(" "),s("p",[t._v("在本节中，我们将使用"),s("a",{attrs:{href:"img/fig2-5.png"}},[t._v("图2-5")]),t._v("所示的示例。它可以从社交网络或系谱数据库中获得：它显示了两个人，来自爱达荷州的Lucy和来自法国Beaune的Alain。他们已婚，住在伦敦。")]),t._v(" "),s("p",[s("img",{attrs:{src:"img/fig2-5.png",alt:""}})]),t._v(" "),s("p",[s("strong",[t._v("图2-5 图数据结构示例（框代表顶点，箭头代表边）")])]),t._v(" "),s("p",[t._v("有几种不同但相关的方法用来构建和查询图表中的数据。在本节中，我们将讨论属性图模型（由Neo4j，Titan和InfiniteGraph实现）和三元组存储（triple-store）模型（由Datomic，AllegroGraph等实现）。我们将查看图的三种声明式查询语言：Cypher，SPARQL和Datalog。除此之外，还有像Gremlin 【36】这样的图形查询语言和像Pregel这样的图形处理框架（见"),s("RouterLink",{attrs:{to:"/ddia/ch10.html"}},[t._v("第10章")]),t._v("）。")],1),t._v(" "),s("h3",{attrs:{id:"属性图"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#属性图"}},[t._v("#")]),t._v(" 属性图")]),t._v(" "),s("p",[t._v("在属性图模型中，每个**顶点（vertex）**包括：")]),t._v(" "),s("ul",[s("li",[t._v("唯一的标识符")]),t._v(" "),s("li",[t._v("一组 "),s("strong",[t._v("出边（outgoing edges）")])]),t._v(" "),s("li",[t._v("一组 "),s("strong",[t._v("入边（ingoing edges）")])]),t._v(" "),s("li",[t._v("一组属性（键值对）")])]),t._v(" "),s("p",[t._v("每条 "),s("strong",[t._v("边（edge）")]),t._v(" 包括：")]),t._v(" "),s("ul",[s("li",[t._v("唯一标识符")]),t._v(" "),s("li",[s("strong",[t._v("边的起点/尾部顶点（tail vertex）")])]),t._v(" "),s("li",[s("strong",[t._v("边的终点/头部顶点（head vertex）")])]),t._v(" "),s("li",[t._v("描述两个顶点之间关系类型的标签")]),t._v(" "),s("li",[t._v("一组属性（键值对）")])]),t._v(" "),s("p",[t._v("可以将图存储看作由两个关系表组成：一个存储顶点，另一个存储边，如"),s("a",{attrs:{href:""}},[t._v("例2-2")]),t._v("所示（该模式使用PostgreSQL json数据类型来存储每个顶点或每条边的属性）。头部和尾部顶点用来存储每条边；如果你想要一组顶点的输入或输出边，你可以分别通过"),s("code",[t._v("head_vertex")]),t._v("或"),s("code",[t._v("tail_vertex")]),t._v("来查询"),s("code",[t._v("edges")]),t._v("表。")]),t._v(" "),s("p",[s("strong",[t._v("例2-2 使用关系模式来表示属性图")])]),t._v(" "),s("div",{staticClass:"language-sql extra-class"},[s("pre",{pre:!0,attrs:{class:"language-sql"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("CREATE")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("TABLE")]),t._v(" vertices "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n  vertex_id  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("INTEGER")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("PRIMARY")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("KEY")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  properties JSON\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("CREATE")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("TABLE")]),t._v(" edges "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n  edge_id     "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("INTEGER")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("PRIMARY")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("KEY")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  tail_vertex "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("INTEGER")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("REFERENCES")]),t._v(" vertices "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("vertex_id"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  head_vertex "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("INTEGER")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("REFERENCES")]),t._v(" vertices "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("vertex_id"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  label       "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("TEXT")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  properties  JSON\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("CREATE")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("INDEX")]),t._v(" edges_tails "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("ON")]),t._v(" edges "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("tail_vertex"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("CREATE")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("INDEX")]),t._v(" edges_heads "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("ON")]),t._v(" edges "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("head_vertex"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),s("p",[t._v("关于这个模型的一些重要方面是：")]),t._v(" "),s("ol",[s("li",[t._v("任何顶点都可以有一条边连接到任何其他顶点。没有模式限制哪种事物可不可以关联。")]),t._v(" "),s("li",[t._v("给定任何顶点，可以高效地找到它的入边和出边，从而遍历图，即沿着一系列顶点的路径前后移动。（这就是为什么"),s("a",{attrs:{href:""}},[t._v("例2-2")]),t._v("在"),s("code",[t._v("tail_vertex")]),t._v("和"),s("code",[t._v("head_vertex")]),t._v("列上都有索引的原因。）")]),t._v(" "),s("li",[t._v("通过对不同类型的关系使用不同的标签，可以在一个图中存储几种不同的信息，同时仍然保持一个清晰的数据模型。")])]),t._v(" "),s("p",[t._v("这些特性为数据建模提供了很大的灵活性，如"),s("a",{attrs:{href:"img/fig2-5.png"}},[t._v("图2-5")]),t._v("所示。图中显示了一些传统关系模式难以表达的事情，例如不同国家的不同地区结构（法国有省和州，美国有不同的州和州），国中国的怪事（先忽略主权国家和国家错综复杂的烂摊子），不同的数据粒度（Lucy现在的住所被指定为一个城市，而她的出生地点只是在一个州的级别）。")]),t._v(" "),s("p",[t._v("你可以想象延伸图还能包括许多关于Lucy和Alain，或其他人的其他更多的事实。例如，你可以用它来表示食物过敏（为每个过敏源增加一个顶点，并增加人与过敏源之间的一条边来指示一种过敏情况），并链接到过敏源，每个过敏源具有一组顶点用来显示哪些食物含有哪些物质。然后，你可以写一个查询，找出每个人吃什么是安全的。图表在可演化性是富有优势的：当向应用程序添加功能时，可以轻松扩展图以适应应用程序数据结构的变化。")]),t._v(" "),s("h3",{attrs:{id:"cypher查询语言"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#cypher查询语言"}},[t._v("#")]),t._v(" Cypher查询语言")]),t._v(" "),s("p",[t._v("Cypher是属性图的声明式查询语言，为Neo4j图形数据库而发明【37】。（它是以电影“黑客帝国”中的一个角色来命名的，而与密码术中的密码无关【38】。）")]),t._v(" "),s("p",[s("a",{attrs:{href:""}},[t._v("例2-3")]),t._v("显示了将"),s("a",{attrs:{href:"img/fig2-5.png"}},[t._v("图2-5")]),t._v("的左边部分插入图形数据库的Cypher查询。可以类似地添加图的其余部分，为了便于阅读而省略。每个顶点都有一个像"),s("code",[t._v("USA")]),t._v("或"),s("code",[t._v("Idaho")]),t._v("这样的符号名称，查询的其他部分可以使用这些名称在顶点之间创建边，使用箭头符号："),s("code",[t._v("（Idaho） - [：WITHIN] ->（USA）")]),t._v("创建一条标记为"),s("code",[t._v("WITHIN")]),t._v("的边，"),s("code",[t._v("Idaho")]),t._v("为尾节点，"),s("code",[t._v("USA")]),t._v("为头节点。")]),t._v(" "),s("p",[s("strong",[t._v("例2-3 将图2-5中的数据子集表示为Cypher查询")])]),t._v(" "),s("div",{staticClass:"language-cypher extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[t._v("CREATE\n\t(NAmerica:Location {name:'North America', type:'continent'}),\n\t(USA:Location      {name:'United States', type:'country'  }),\n\t(Idaho:Location    {name:'Idaho',         type:'state'    }),\n\t(Lucy:Person       {name:'Lucy' }),\n\t(Idaho) -[:WITHIN]->  (USA)  -[:WITHIN]-> (NAmerica),\n\t(Lucy)  -[:BORN_IN]-> (Idaho)\n")])])]),s("p",[t._v("当"),s("a",{attrs:{href:"img/fig2-5.png"}},[t._v("图2-5")]),t._v("的所有顶点和边被添加到数据库后，让我们提些有趣的问题：例如，找到所有从美国移民到欧洲的人的名字。更确切地说，这里我们想要找到符合下面条件的所有顶点，并且返回这些顶点的"),s("code",[t._v("name")]),t._v("属性：该顶点拥有一条连到美国任一位置的"),s("code",[t._v("BORN_IN")]),t._v("边，和一条连到欧洲的任一位置的"),s("code",[t._v("LIVING_IN")]),t._v("边。")]),t._v(" "),s("p",[s("a",{attrs:{href:""}},[t._v("例2-4")]),t._v("展示了如何在Cypher中表达这个查询。在MATCH子句中使用相同的箭头符号来查找图中的模式："),s("code",[t._v("(person) -[:BORN_IN]-> ()")]),t._v(" 可以匹配"),s("code",[t._v("BORN_IN")]),t._v("边的任意两个顶点。该边的尾节点被绑定了变量"),s("code",[t._v("person")]),t._v("，头节点则未被绑定。")]),t._v(" "),s("p",[s("strong",[t._v("例2-4 查找所有从美国移民到欧洲的人的Cypher查询：")])]),t._v(" "),s("div",{staticClass:"language-cypher extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[t._v("MATCH\n\t(person) -[:BORN_IN]->  () -[:WITHIN*0..]-> (us:Location {name:'United States'}),\n\t(person) -[:LIVES_IN]-> () -[:WITHIN*0..]-> (eu:Location {name:'Europe'})\nRETURN person.name\n")])])]),s("p",[t._v("查询按如下来解读：")]),t._v(" "),s("blockquote",[s("p",[t._v("找到满足以下两个条件的所有顶点（称之为person顶点）：")]),t._v(" "),s("ol",[s("li",[s("p",[s("code",[t._v("person")]),t._v("顶点拥有一条到某个顶点的"),s("code",[t._v("BORN_IN")]),t._v("出边。从那个顶点开始，沿着一系列"),s("code",[t._v("WITHIN")]),t._v("出边最终到达一个类型为"),s("code",[t._v("Location")]),t._v("，"),s("code",[t._v("name")]),t._v("属性为"),s("code",[t._v("United States")]),t._v("的顶点。")])]),t._v(" "),s("li",[s("p",[s("code",[t._v("person")]),t._v("顶点还拥有一条"),s("code",[t._v("LIVES_IN")]),t._v("出边。沿着这条边，可以通过一系列"),s("code",[t._v("WITHIN")]),t._v("出边最终到达一个类型为"),s("code",[t._v("Location")]),t._v("，"),s("code",[t._v("name")]),t._v("属性为"),s("code",[t._v("Europe")]),t._v("的顶点。")])])]),t._v(" "),s("p",[t._v("对于这样的"),s("code",[t._v("Person")]),t._v("顶点，返回其"),s("code",[t._v("name")]),t._v("属性。")])]),t._v(" "),s("p",[t._v("执行这条查询可能会有几种可行的查询路径。这里给出的描述建议首先扫描数据库中的所有人，检查每个人的出生地和居住地，然后只返回符合条件的那些人。")]),t._v(" "),s("p",[t._v("等价地，也可以从两个"),s("code",[t._v("Location")]),t._v("顶点开始反向地查找。假如"),s("code",[t._v("name")]),t._v("属性上有索引，则可以高效地找到代表美国和欧洲的两个顶点。然后，沿着所有"),s("code",[t._v("WITHIN")]),t._v("入边，可以继续查找出所有在美国和欧洲的位置（州，地区，城市等）。最后，查找出那些可以由"),s("code",[t._v("BORN_IN")]),t._v("或"),s("code",[t._v("LIVES_IN")]),t._v("入边到那些位置顶点的人。")]),t._v(" "),s("p",[t._v("通常对于声明式查询语言来说，在编写查询语句时，不需要指定执行细节：查询优化程序会自动选择预测效率最高的策略，因此你可以继续编写应用程序的其他部分。")]),t._v(" "),s("h3",{attrs:{id:"sql中的图查询"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#sql中的图查询"}},[t._v("#")]),t._v(" SQL中的图查询")]),t._v(" "),s("p",[s("a",{attrs:{href:""}},[t._v("例2-2")]),t._v("建议在关系数据库中表示图数据。但是，如果把图数据放入关系结构中，我们是否也可以使用SQL查询它？")]),t._v(" "),s("p",[t._v("答案是肯定的，但有些困难。在关系数据库中，你通常会事先知道在查询中需要哪些连接。在图查询中，你可能需要在找到待查找的顶点之前，遍历可变数量的边。也就是说，连接的数量事先并不确定。")]),t._v(" "),s("p",[t._v("在我们的例子中，这发生在Cypher查询中的"),s("code",[t._v("() -[:WITHIN*0..]-> ()")]),t._v("规则中。一个人的"),s("code",[t._v("LIVES_IN")]),t._v("边可以指向任何类型的位置：街道，城市，地区，地区，国家等。城市可以在一个地区，在一个州内的一个地区，在一个国家内的一个州等等。"),s("code",[t._v("LIVES_IN")]),t._v("边可以直接指向正在查找的位置，或者一个在位置层次结构中隔了数层的位置。")]),t._v(" "),s("p",[t._v("在Cypher中，用"),s("code",[t._v("WITHIN * 0")]),t._v("非常简洁地表述了上述事实：“沿着"),s("code",[t._v("WITHIN")]),t._v("边，零次或多次”。它很像正则表达式中的"),s("code",[t._v("*")]),t._v("运算符。")]),t._v(" "),s("p",[t._v("自SQL:1999，查询可变长度遍历路径的思想可以使用称为"),s("strong",[t._v("递归公用表表达式")]),t._v("（"),s("code",[t._v("WITH RECURSIVE")]),t._v("语法）的东西来表示。"),s("a",{attrs:{href:""}},[t._v("例2-5")]),t._v("显示了同样的查询 - 查找从美国移民到欧洲的人的姓名 - 在SQL使用这种技术（PostgreSQL，IBM DB2，Oracle和SQL Server均支持）来表述。但是，与Cypher相比，其语法非常笨拙。")]),t._v(" "),s("p",[s("strong",[t._v("例2-5  与示例2-4同样的查询，在SQL中使用递归公用表表达式表示")])]),t._v(" "),s("div",{staticClass:"language-sql extra-class"},[s("pre",{pre:!0,attrs:{class:"language-sql"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("WITH")]),t._v(" RECURSIVE\n  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("-- in_usa 包含所有的美国境内的位置ID")]),t._v("\n    in_usa"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("vertex_id"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("AS")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("SELECT")]),t._v(" vertex_id "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("FROM")]),t._v(" vertices "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("WHERE")]),t._v(" properties "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">>")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'name'")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'United States'")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("UNION")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("SELECT")]),t._v(" edges"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("tail_vertex "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("FROM")]),t._v(" edges\n      "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("JOIN")]),t._v(" in_usa "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("ON")]),t._v(" edges"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("head_vertex "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" in_usa"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("vertex_id\n      "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("WHERE")]),t._v(" edges"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("label "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'within'")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("-- in_europe 包含所有的欧洲境内的位置ID")]),t._v("\n    in_europe"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("vertex_id"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("AS")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("SELECT")]),t._v(" vertex_id "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("FROM")]),t._v(" vertices "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("WHERE")]),t._v(" properties "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">>")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'name'")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Europe'")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("UNION")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("SELECT")]),t._v(" edges"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("tail_vertex "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("FROM")]),t._v(" edges\n      "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("JOIN")]),t._v(" in_europe "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("ON")]),t._v(" edges"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("head_vertex "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" in_europe"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("vertex_id\n      "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("WHERE")]),t._v(" edges"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("label "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'within'")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n\n  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("-- born_in_usa 包含了所有类型为Person，且出生在美国的顶点")]),t._v("\n    born_in_usa"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("vertex_id"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("AS")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("SELECT")]),t._v(" edges"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("tail_vertex "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("FROM")]),t._v(" edges\n        "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("JOIN")]),t._v(" in_usa "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("ON")]),t._v(" edges"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("head_vertex "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" in_usa"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("vertex_id\n        "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("WHERE")]),t._v(" edges"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("label "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'born_in'")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n\n  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("-- lives_in_europe 包含了所有类型为Person，且居住在欧洲的顶点。")]),t._v("\n    lives_in_europe"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("vertex_id"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("AS")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("SELECT")]),t._v(" edges"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("tail_vertex "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("FROM")]),t._v(" edges\n        "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("JOIN")]),t._v(" in_europe "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("ON")]),t._v(" edges"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("head_vertex "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" in_europe"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("vertex_id\n        "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("WHERE")]),t._v(" edges"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("label "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'lives_in'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("SELECT")]),t._v(" vertices"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("properties "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">>")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'name'")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("FROM")]),t._v(" vertices\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("JOIN")]),t._v(" born_in_usa "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("ON")]),t._v(" vertices"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("vertex_id "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" born_in_usa"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("vertex_id\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("JOIN")]),t._v(" lives_in_europe "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("ON")]),t._v(" vertices"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("vertex_id "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" lives_in_europe"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("vertex_id"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),s("ul",[s("li",[t._v("首先，查找"),s("code",[t._v("name")]),t._v("属性为"),s("code",[t._v("United States")]),t._v("的顶点，将其作为"),s("code",[t._v("in_usa")]),t._v("顶点的集合的第一个元素。")]),t._v(" "),s("li",[t._v("从"),s("code",[t._v("in_usa")]),t._v("集合的顶点出发，沿着所有的"),s("code",[t._v("with_in")]),t._v("入边，将其尾顶点加入同一集合，不断递归直到所有"),s("code",[t._v("with_in")]),t._v("入边都被访问完毕。")]),t._v(" "),s("li",[t._v("同理，从"),s("code",[t._v("name")]),t._v("属性为"),s("code",[t._v("Europe")]),t._v("的顶点出发，建立"),s("code",[t._v("in_europe")]),t._v("顶点的集合。")]),t._v(" "),s("li",[t._v("对于"),s("code",[t._v("in_usa")]),t._v("集合中的每个顶点，根据"),s("code",[t._v("born_in")]),t._v("入边来查找出生在美国某个地方的人。")]),t._v(" "),s("li",[t._v("同样，对于"),s("code",[t._v("in_europe")]),t._v("集合中的每个顶点，根据"),s("code",[t._v("lives_in")]),t._v("入边来查找居住在欧洲的人。")]),t._v(" "),s("li",[t._v("最后，把在美国出生的人的集合与在欧洲居住的人的集合相交。")])]),t._v(" "),s("p",[t._v("同一个查询，用某一个查询语言可以写成4行，而用另一个查询语言需要29行，这恰恰说明了不同的数据模型是为不同的应用场景而设计的。选择适合应用程序的数据模型非常重要。")]),t._v(" "),s("h3",{attrs:{id:"三元组存储和sparql"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#三元组存储和sparql"}},[t._v("#")]),t._v(" 三元组存储和SPARQL")]),t._v(" "),s("p",[t._v("三元组存储模式大体上与属性图模型相同，用不同的词来描述相同的想法。不过仍然值得讨论，因为三元组存储有很多现成的工具和语言，这些工具和语言对于构建应用程序的工具箱可能是宝贵的补充。")]),t._v(" "),s("p",[t._v("在三元组存储中，所有信息都以非常简单的三部分表示形式存储（"),s("strong",[t._v("主语")]),t._v("，"),s("strong",[t._v("谓语")]),t._v("，"),s("strong",[t._v("宾语")]),t._v("）。例如，三元组 "),s("strong",[t._v("(吉姆, 喜欢 ,香蕉)")]),t._v(" 中，"),s("strong",[t._v("吉姆")]),t._v(" 是主语，"),s("strong",[t._v("喜欢")]),t._v(" 是谓语（动词），"),s("strong",[t._v("香蕉")]),t._v(" 是对象。")]),t._v(" "),s("p",[t._v("三元组的主语相当于图中的一个顶点。而宾语是下面两者之一：")]),t._v(" "),s("ol",[s("li",[t._v("原始数据类型中的值，例如字符串或数字。在这种情况下，三元组的谓语和宾语相当于主语顶点上的属性的键和值。例如，"),s("code",[t._v("(lucy, age, 33)")]),t._v("就像属性"),s("code",[t._v("{“age”：33}")]),t._v("的顶点lucy。")]),t._v(" "),s("li",[t._v("图中的另一个顶点。在这种情况下，谓语是图中的一条边，主语是其尾部顶点，而宾语是其头部顶点。例如，在"),s("code",[t._v("(lucy, marriedTo, alain)")]),t._v("中主语和宾语"),s("code",[t._v("lucy")]),t._v("和"),s("code",[t._v("alain")]),t._v("都是顶点，并且谓语"),s("code",[t._v("marriedTo")]),t._v("是连接他们的边的标签。")])]),t._v(" "),s("p",[s("a",{attrs:{href:""}},[t._v("例2-6")]),t._v("显示了与"),s("a",{attrs:{href:""}},[t._v("例2-3")]),t._v("相同的数据，以称为Turtle的格式（Notation3（N3）【39】）的一个子集形式写成三元组。")]),t._v(" "),s("p",[s("strong",[t._v("例2-6 图2-5中的数据子集，表示为Turtle三元组")])]),t._v(" "),s("div",{staticClass:"language-reStructuredText extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[t._v('@prefix : <urn:example:>.\n_:lucy     a       :Person.\n_:lucy     :name   "Lucy".\n_:lucy     :bornIn _:idaho.\n_:idaho    a       :Location.\n_:idaho    :name   "Idaho".\n_:idaho    :type   "state".\n_:idaho    :within _:usa.\n_:usa      a       :Location\n_:usa      :name   "United States"\n_:usa      :type   "country".\n_:usa      :within _:namerica.\n_:namerica a       :Location\n_:namerica :name   "North America"\n_:namerica :type   :"continent"\n')])])]),s("p",[t._v("在这个例子中，图的顶点被写为："),s("code",[t._v("_：someName")]),t._v("。这个名字并不意味着这个文件以外的任何东西。它的存在只是帮助我们明确哪些三元组引用了同一顶点。当谓语表示边时，该宾语是一个顶点，如"),s("code",[t._v("_:idaho :within _:usa.")]),t._v("。当谓语是一个属性时，该宾语是一个字符串，如"),s("code",[t._v('_:usa :name "United States"')])]),t._v(" "),s("p",[t._v("一遍又一遍地重复相同的主语看起来相当重复，但幸运的是，可以使用分号来说明关于同一主语的多个事情。这使得Turtle格式相当不错，可读性强：参见"),s("a",{attrs:{href:""}},[t._v("例2-7")]),t._v("。")]),t._v(" "),s("p",[s("strong",[t._v("例2-7 一种相对例2-6写入数据的更为简洁的方法。")])]),t._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[t._v('@prefix : <urn:example:>.\n_:lucy      a :Person;   :name "Lucy";          :bornIn _:idaho.\n_:idaho     a :Location; :name "Idaho";         :type "state";   :within _:usa\n_:usa       a :Loaction; :name "United States"; :type "country"; :within _:namerica.\n_:namerica  a :Location; :name "North America"; :type "continent".\n')])])]),s("h4",{attrs:{id:"语义网络"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#语义网络"}},[t._v("#")]),t._v(" 语义网络")]),t._v(" "),s("p",[t._v("如果你阅读更多关于三元组存储的信息，你可能会被卷入关于语义网络的文章漩涡中。三元组存储数据模型完全独立于语义网络，例如，Datomic【40】是三元组存储"),s("a",{attrs:{href:"%E4%BB%8E%E6%8A%80%E6%9C%AF%E4%B8%8A%E8%AE%B2%EF%BC%8CDatomic%E4%BD%BF%E7%94%A8%E7%9A%84%E6%98%AF%E4%BA%94%E5%85%83%E7%BB%84%E8%80%8C%E4%B8%8D%E6%98%AF%E4%B8%89%E5%85%83%E7%BB%84%EF%BC%8C%E4%B8%A4%E4%B8%AA%E9%A2%9D%E5%A4%96%E7%9A%84%E5%AD%97%E6%AE%B5%E6%98%AF%E7%94%A8%E4%BA%8E%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6%E7%9A%84%E5%85%83%E6%95%B0%E6%8D%AE"}},[t._v("^vii")]),t._v("，并没有声称与它有任何关系。但是，由于在很多人眼中这两者紧密相连，我们应该简要地讨论一下。")]),t._v(" "),s("p",[t._v("从本质上讲语义网是一个简单且合理的想法：网站已经将信息发布为文字和图片供人类阅读，为什么不将信息作为机器可读的数据也发布给计算机呢？"),s("strong",[t._v("资源描述框架")]),t._v("（RDF）【41】的目的是作为不同网站以一致的格式发布数据的一种机制，允许来自不同网站的数据自动合并成"),s("strong",[t._v("一个数据网络")]),t._v(" - 一种互联网范围内的“关于一切的数据库“。")]),t._v(" "),s("p",[t._v("不幸的是，这个语义网在二十一世纪初被过度使用，但到目前为止没有任何迹象表明已在实践中实现，这使得许多人呲之以鼻。它还遭受了过多的令人眼花缭乱的缩略词，过于复杂的标准提议和狂妄自大的苦果。")]),t._v(" "),s("p",[t._v("然而，如果仔细观察这些失败，语义Web项目还是拥有很多优秀的工作成果。即使你没有兴趣在语义网上发布RDF数据，三元组也可以成为应用程序的良好内部数据模型。")]),t._v(" "),s("h4",{attrs:{id:"rdf数据模型"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#rdf数据模型"}},[t._v("#")]),t._v(" RDF数据模型")]),t._v(" "),s("p",[s("a",{attrs:{href:""}},[t._v("例2-7")]),t._v("中使用的Turtle语言是一种用于RDF数据的人可读格式。有时候，RDF也可以以XML格式编写，不过完成同样的事情会相对啰嗦，参见"),s("a",{attrs:{href:""}},[t._v("例2-8")]),t._v("。Turtle/N3是更可取的，因为它更容易阅读，像Apache Jena 【42】这样的工具可以根据需要在不同的RDF格式之间进行自动转换。")]),t._v(" "),s("p",[s("strong",[t._v("例2-8 用RDF/XML语法表示例2-7的数据")])]),t._v(" "),s("div",{staticClass:"language-xml extra-class"},[s("pre",{pre:!0,attrs:{class:"language-xml"}},[s("code",[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("rdf:")]),t._v("RDF")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("xmlns")]),s("span",{pre:!0,attrs:{class:"token attr-value"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')]),t._v("urn:example:"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')])]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[s("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("xmlns:")]),t._v("rdf")]),s("span",{pre:!0,attrs:{class:"token attr-value"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')]),t._v("http://www.w3.org/1999/02/22-rdf-syntax-ns#"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')])]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("Location")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[s("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("rdf:")]),t._v("nodeID")]),s("span",{pre:!0,attrs:{class:"token attr-value"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')]),t._v("idaho"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')])]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("name")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("Idaho"),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("name")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("type")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("state"),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("type")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("within")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("Location")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[s("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("rdf:")]),t._v("nodeID")]),s("span",{pre:!0,attrs:{class:"token attr-value"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')]),t._v("usa"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')])]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                "),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("name")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("United States"),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("name")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                "),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("type")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("country"),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("type")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                "),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("within")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                    "),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("Location")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[s("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("rdf:")]),t._v("nodeID")]),s("span",{pre:!0,attrs:{class:"token attr-value"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')]),t._v("namerica"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')])]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                        "),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("name")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("North America"),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("name")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                        "),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("type")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("continent"),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("type")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                    "),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("Location")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                "),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("within")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("Location")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("within")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("Location")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("Person")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[s("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("rdf:")]),t._v("nodeID")]),s("span",{pre:!0,attrs:{class:"token attr-value"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')]),t._v("lucy"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')])]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("name")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("Lucy"),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("name")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("bornIn")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[s("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("rdf:")]),t._v("nodeID")]),s("span",{pre:!0,attrs:{class:"token attr-value"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')]),t._v("idaho"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')])]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("/>")])]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("Person")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),s("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("rdf:")]),t._v("RDF")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n")])])]),s("p",[t._v("RDF有一些奇怪之处，因为它是为了在互联网上交换数据而设计的。三元组的主语，谓语和宾语通常是URI。例如，谓语可能是一个URI，如 "),s("code",[t._v("<http://my-company.com/namespace#within>")]),t._v("或"),s("code",[t._v("<http://my-company.com/namespace#lives_in>")]),t._v("，而不仅仅是"),s("code",[t._v("WITHIN")]),t._v("或"),s("code",[t._v("LIVES_IN")]),t._v("。这个设计背后的原因为了让你能够把你的数据和其他人的数据结合起来，如果他们赋予单词"),s("code",[t._v("within")]),t._v("或者"),s("code",[t._v("lives_in")]),t._v("不同的含义，两者也不会冲突，因为它们的谓语实际上是"),s("code",[t._v("<http://other.org/foo#within>")]),t._v("和"),s("code",[t._v("<http://other.org/foo#lives_in>")]),t._v("。")]),t._v(" "),s("p",[t._v("从RDF的角度来看，URL "),s("code",[t._v("<http://my-company.com/namespace>")]),t._v(" 不一定需要能解析成什么东西，它只是一个命名空间。为避免与"),s("code",[t._v("http://URL")]),t._v("混淆，本节中的示例使用不可解析的URI，如"),s("code",[t._v("urn：example：within")]),t._v("。幸运的是，你只需在文件顶部指定一个前缀，然后就不用再管了。")]),t._v(" "),s("h3",{attrs:{id:"sparql查询语言"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#sparql查询语言"}},[t._v("#")]),t._v(" SPARQL查询语言")]),t._v(" "),s("p",[s("strong",[t._v("SPARQL")]),t._v("是一种用于三元组存储的面向RDF数据模型的查询语言，【43】。（它是SPARQL协议和RDF查询语言的缩写，发音为“sparkle”。）SPARQL早于Cypher，并且由于Cypher的模式匹配借鉴于SPARQL，这使得它们看起来非常相似【37】。")]),t._v(" "),s("p",[t._v("与之前相同的查询 - 查找从美国转移到欧洲的人 - 使用SPARQL比使用Cypher甚至更为简洁（参见"),s("a",{attrs:{href:""}},[t._v("例2-9")]),t._v("）。")]),t._v(" "),s("p",[s("strong",[t._v("例2-9 与示例2-4相同的查询，用SPARQL表示")])]),t._v(" "),s("div",{staticClass:"language-sparql extra-class"},[s("pre",{pre:!0,attrs:{class:"language-sparql"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("PREFIX")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[s("span",{pre:!0,attrs:{class:"token prefix"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")])])]),t._v(" "),s("span",{pre:!0,attrs:{class:"token url"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("urn:example:"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("SELECT")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token variable"}},[t._v("?personName")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("WHERE")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token variable"}},[t._v("?person")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[s("span",{pre:!0,attrs:{class:"token prefix"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")])]),s("span",{pre:!0,attrs:{class:"token local-name"}},[t._v("name")])]),t._v(" "),s("span",{pre:!0,attrs:{class:"token variable"}},[t._v("?personName")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token variable"}},[t._v("?person")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[s("span",{pre:!0,attrs:{class:"token prefix"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")])]),s("span",{pre:!0,attrs:{class:"token local-name"}},[t._v("bornIn")])]),t._v("  / "),s("span",{pre:!0,attrs:{class:"token function"}},[s("span",{pre:!0,attrs:{class:"token prefix"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")])]),s("span",{pre:!0,attrs:{class:"token local-name"}},[t._v("within")])]),t._v("* / "),s("span",{pre:!0,attrs:{class:"token function"}},[s("span",{pre:!0,attrs:{class:"token prefix"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")])]),s("span",{pre:!0,attrs:{class:"token local-name"}},[t._v("name")])]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"United States"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token variable"}},[t._v("?person")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[s("span",{pre:!0,attrs:{class:"token prefix"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")])]),s("span",{pre:!0,attrs:{class:"token local-name"}},[t._v("livesIn")])]),t._v(" / "),s("span",{pre:!0,attrs:{class:"token function"}},[s("span",{pre:!0,attrs:{class:"token prefix"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")])]),s("span",{pre:!0,attrs:{class:"token local-name"}},[t._v("within")])]),t._v("* / "),s("span",{pre:!0,attrs:{class:"token function"}},[s("span",{pre:!0,attrs:{class:"token prefix"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")])]),s("span",{pre:!0,attrs:{class:"token local-name"}},[t._v("name")])]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Europe"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),s("p",[t._v("结构非常相似。以下两个表达式是等价的（SPARQL中的变量以问号开头）：")]),t._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[t._v("(person) -[:BORN_IN]-> () -[:WITHIN*0..]-> (location)   # Cypher\n?person :bornIn / :within* ?location.                   # SPARQL\n")])])]),s("p",[t._v("因为RDF不区分属性和边，而只是将它们作为谓语，所以可以使用相同的语法来匹配属性。在下面的表达式中，变量"),s("code",[t._v("usa")]),t._v("被绑定到任意具有值为字符串"),s("code",[t._v('"United States"')]),t._v("的"),s("code",[t._v("name")]),t._v("属性的顶点：")]),t._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[t._v("(usa {name:'United States'})   # Cypher\n?usa :name \"United States\".    # SPARQL\n")])])]),s("p",[t._v("SPARQL是一种很好的查询语言——哪怕语义网从未实现，它仍然可以成为一种应用程序内部使用的强大工具。")]),t._v(" "),s("blockquote",[s("h4",{attrs:{id:"图形数据库与网络模型相比较"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#图形数据库与网络模型相比较"}},[t._v("#")]),t._v(" 图形数据库与网络模型相比较")]),t._v(" "),s("p",[t._v("在“"),s("a",{attrs:{href:"#%E6%96%87%E6%A1%A3%E6%95%B0%E6%8D%AE%E5%BA%93%E6%98%AF%E5%90%A6%E5%9C%A8%E9%87%8D%E8%B9%88%E8%A6%86%E8%BE%99%EF%BC%9F"}},[t._v("文档数据库是否在重蹈覆辙？")]),t._v("”中，我们讨论了CODASYL和关系模型如何竞相解决IMS中的多对多关系问题。乍一看，CODASYL的网络模型看起来与图模型相似。CODASYL是否是图形数据库的第二个变种？")]),t._v(" "),s("p",[t._v("不，他们在几个重要方面有所不同：")]),t._v(" "),s("ul",[s("li",[t._v("在CODASYL中，数据库有一个模式，用于指定哪种记录类型可以嵌套在其他记录类型中。在图形数据库中，不存在这样的限制：任何顶点都可以具有到其他任何顶点的边。这为应用程序适应不断变化的需求提供了更大的灵活性。")]),t._v(" "),s("li",[t._v("在CODASYL中，达到特定记录的唯一方法是遍历其中的一个访问路径。在图形数据库中，可以通过其唯一ID直接引用任何顶点，也可以使用索引来查找具有特定值的顶点。")]),t._v(" "),s("li",[t._v("在CODASYL，记录的后续是一个有序集合，所以数据库的人不得不维持排序（这会影响存储布局），并且插入新记录到数据库的应用程序不得不担心的新记录在这些集合中的位置。在图形数据库中，顶点和边不是有序的（只能在查询时对结果进行排序）。")]),t._v(" "),s("li",[t._v("在CODASYL中，所有查询都是命令式的，难以编写，并且很容易因架构中的变化而受到破坏。在图形数据库中，如果需要，可以在命令式代码中编写遍历，但大多数图形数据库也支持高级声明式查询语言，如Cypher或SPARQL。")])])]),t._v(" "),s("h3",{attrs:{id:"基础：datalog"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#基础：datalog"}},[t._v("#")]),t._v(" 基础：Datalog")]),t._v(" "),s("p",[s("strong",[t._v("Datalog")]),t._v("是比SPARQL或Cypher更古老的语言，在20世纪80年代被学者广泛研究【44,45,46】。它在软件工程师中不太知名，但是它是重要的，因为它为以后的查询语言提供了基础。")]),t._v(" "),s("p",[t._v("在实践中，Datalog被用于少数的数据系统中：例如，它是Datomic 【40】的查询语言，Cascalog 【47】是一种用于查询Hadoop大数据集的Datalog实现[^viii]。")]),t._v(" "),s("p",[t._v("[^viii]: Datomic和Cascalog使用Datalog的Clojure S表达式语法。在下面的例子中使用了一个更容易阅读的Prolog语法，但两者没有任何功能差异。")]),t._v(" "),s("p",[t._v("Datalog的数据模型类似于三元组模式，但进行了一点泛化。把三元组写成"),s("strong",[t._v("谓语")]),t._v("（"),s("strong",[t._v("主语，宾语")]),t._v("），而不是写三元语（"),s("strong",[t._v("主语，谓语，宾语")]),t._v("）。"),s("a",{attrs:{href:""}},[t._v("例2-10")]),t._v("显示了如何用Datalog写入我们的例子中的数据。")]),t._v(" "),s("p",[s("strong",[t._v("例2-10 用Datalog来表示图2-5中的数据子集")])]),t._v(" "),s("div",{staticClass:"language-prolog extra-class"},[s("pre",{pre:!0,attrs:{class:"language-prolog"}},[s("code",[s("span",{pre:!0,attrs:{class:"token function"}},[t._v("name")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("namerica"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'North America'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(".")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("type")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("namerica"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" continent"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(".")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("name")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("usa"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'United States'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(".")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("type")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("usa"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" country"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(".")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("within")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("usa"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" namerica"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(".")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("name")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("idaho"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Idaho'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(".")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("type")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("idaho"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" state"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(".")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("within")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("idaho"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" usa"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(".")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("name")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("lucy"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Lucy'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(".")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("born_in")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("lucy"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" idaho"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(".")]),t._v("\n")])])]),s("p",[t._v("既然已经定义了数据，我们可以像之前一样编写相同的查询，如"),s("a",{attrs:{href:""}},[t._v("例2-11")]),t._v("所示。它看起来有点不同于Cypher或SPARQL的等价物，但是请不要放弃它。Datalog是Prolog的一个子集，如果你学过计算机科学，你可能已经见过。")]),t._v(" "),s("p",[s("strong",[t._v("例2-11 与示例2-4相同的查询，用Datalog表示")])]),t._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[t._v("within_recursive(Location, Name) :- name(Location, Name). /* Rule 1 */\n\nwithin_recursive(Location, Name) :- within(Location, Via), /* Rule 2 */\n\t\t\t\t\t\t\t\t\twithin_recursive(Via, Name).\n\nmigrated(Name, BornIn, LivingIn) :- name(Person, Name), /* Rule 3 */\n                                    born_in(Person, BornLoc),\n                                    within_recursive(BornLoc, BornIn),\n                                    lives_in(Person, LivingLoc),\n                                    within_recursive(LivingLoc, LivingIn).\n\n?- migrated(Who, 'United States', 'Europe'). /* Who = 'Lucy'. */\n\n")])])]),s("p",[t._v("Cypher和SPARQL使用SELECT立即跳转，但是Datalog一次只进行一小步。我们定义"),s("strong",[t._v("规则")]),t._v("，以将新谓语告诉数据库：在这里，我们定义了两个新的谓语，"),s("code",[t._v("within_recursive")]),t._v("和"),s("code",[t._v("migrated")]),t._v("。这些谓语不是存储在数据库中的三元组中，而是它们是从数据或其他规则派生而来的。规则可以引用其他规则，就像函数可以调用其他函数或者递归地调用自己一样。像这样，复杂的查询可以一次构建其中的一小块。")]),t._v(" "),s("p",[t._v("在规则中，以大写字母开头的单词是变量，谓语则用Cypher和SPARQL的方式一样来匹配。例如，"),s("code",[t._v("name(Location, Name)")]),t._v("通过变量绑定"),s("code",[t._v("Location = namerica")]),t._v("和"),s("code",[t._v("Name ='North America'")]),t._v("可以匹配三元组"),s("code",[t._v("name(namerica, 'North America')")]),t._v("。")]),t._v(" "),s("p",[t._v("要是系统可以在"),s("code",[t._v(":-")]),t._v(" 操作符的右侧找到与所有谓语的一个匹配，就运用该规则。当规则运用时，就好像通过"),s("code",[t._v(":-")]),t._v("的左侧将其添加到数据库（将变量替换成它们匹配的值）。")]),t._v(" "),s("p",[t._v("因此，一种可能的应用规则的方式是：")]),t._v(" "),s("ol",[s("li",[t._v("数据库存在"),s("code",[t._v("name(namerica, 'North America')")]),t._v("，故运用规则1。它生成"),s("code",[t._v("within_recursive(namerica, 'North America')")]),t._v("。")]),t._v(" "),s("li",[t._v("数据库存在"),s("code",[t._v("within(usa, namerica)")]),t._v("，在上一步骤中生成"),s("code",[t._v("within_recursive(namerica, 'North America')")]),t._v("，故运用规则2。它会产生"),s("code",[t._v("within_recursive(usa, 'North America')")]),t._v("。")]),t._v(" "),s("li",[t._v("数据库存在"),s("code",[t._v("within(idaho, usa)")]),t._v("，在上一步生成"),s("code",[t._v("within_recursive(usa, 'North America')")]),t._v("，故运用规则2。它产生"),s("code",[t._v("within_recursive(idaho, 'North America')")]),t._v("。")])]),t._v(" "),s("p",[t._v("通过重复应用规则1和2，"),s("code",[t._v("within_recursive")]),t._v("谓语可以告诉我们在数据库中包含北美（或任何其他位置名称）的所有位置。这个过程如"),s("a",{attrs:{href:"img/fig2-6.png"}},[t._v("图2-6")]),t._v("所示。")]),t._v(" "),s("p",[s("img",{attrs:{src:"img/fig2-6.png",alt:""}})]),t._v(" "),s("p",[s("strong",[t._v("图2-6 使用示例2-11中的Datalog规则来确定爱达荷州在北美。")])]),t._v(" "),s("p",[t._v("现在规则3可以找到出生在某个地方"),s("code",[t._v("BornIn")]),t._v("的人，并住在某个地方"),s("code",[t._v("LivingIn")]),t._v("。通过查询"),s("code",[t._v("BornIn ='United States'")]),t._v("和"),s("code",[t._v("LivingIn ='Europe'")]),t._v("，并将此人作为变量"),s("code",[t._v("Who")]),t._v("，让Datalog系统找出变量"),s("code",[t._v("Who")]),t._v("会出现哪些值。因此，最后得到了与早先的Cypher和SPARQL查询相同的答案。")]),t._v(" "),s("p",[t._v("相对于本章讨论的其他查询语言，我们需要采取不同的思维方式来思考Datalog方法，但这是一种非常强大的方法，因为规则可以在不同的查询中进行组合和重用。虽然对于简单的一次性查询，显得不太方便，但是它可以更好地处理数据很复杂的情况。")]),t._v(" "),s("h2",{attrs:{id:"本章小结"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#本章小结"}},[t._v("#")]),t._v(" 本章小结")]),t._v(" "),s("p",[t._v("数据模型是一个巨大的课题，在本章中，我们快速浏览了各种不同的模型。我们没有足够的空间来详细介绍每个模型的细节，但是希望这个概述足以激起你的兴趣，以更多地了解最适合你的应用需求的模型。")]),t._v(" "),s("p",[t._v("在历史上，数据最开始被表示为一棵大树（层次数据模型），但是这不利于表示多对多的关系，所以发明了关系模型来解决这个问题。最近，开发人员发现一些应用程序也不适合采用关系模型。新的非关系型“NoSQL”数据存储在两个主要方向上存在分歧：")]),t._v(" "),s("ol",[s("li",[s("strong",[t._v("文档数据库")]),t._v("的应用场景是：数据通常是自我包含的，而且文档之间的关系非常稀少。")]),t._v(" "),s("li",[s("strong",[t._v("图形数据库")]),t._v("用于相反的场景：任意事物都可能与任何事物相关联。")])]),t._v(" "),s("p",[t._v("这三种模型（文档，关系和图形）在今天都被广泛使用，并且在各自的领域都发挥很好。一个模型可以用另一个模型来模拟 — 例如，图数据可以在关系数据库中表示 — 但结果往往是糟糕的。这就是为什么我们有着针对不同目的的不同系统，而不是一个单一的万能解决方案。")]),t._v(" "),s("p",[t._v("文档数据库和图数据库有一个共同点，那就是它们通常不会为存储的数据强制一个模式，这可以使应用程序更容易适应不断变化的需求。但是应用程序很可能仍会假定数据具有一定的结构；这只是模式是明确的（写入时强制）还是隐含的（读取时处理）的问题。")]),t._v(" "),s("p",[t._v("每个数据模型都具有各自的查询语言或框架，我们讨论了几个例子：SQL，MapReduce，MongoDB的聚合管道，Cypher，SPARQL和Datalog。我们也谈到了CSS和XSL/XPath，它们不是数据库查询语言，而包含有趣的相似之处。")]),t._v(" "),s("p",[t._v("虽然我们已经覆盖了很多层面，但仍然有许多数据模型没有提到。举几个简单的例子：")]),t._v(" "),s("ul",[s("li",[t._v("使用基因组数据的研究人员通常需要执行"),s("strong",[t._v("序列相似性搜索")]),t._v("，这意味着需要一个很长的字符串（代表一个DNA分子），并在一个拥有类似但不完全相同的字符串的大型数据库中寻找匹配。这里所描述的数据库都不能处理这种用法，这就是为什么研究人员编写了像GenBank这样的专门的基因组数据库软件的原因【48】。")]),t._v(" "),s("li",[t._v("粒子物理学家数十年来一直在进行大数据类型的大规模数据分析，像大型强子对撞机（LHC）这样的项目现在可以工作在数百亿兆字节的范围内！在这样的规模下，需要定制解决方案来阻住硬件成本的失控【49】。")]),t._v(" "),s("li",[s("strong",[t._v("全文搜索")]),t._v("可以说是一种经常与数据库一起使用的数据模型。信息检索是一个很大的专业课题，我们不会在本书中详细介绍，但是我们将在第三章和第三章中介绍搜索索引。")])]),t._v(" "),s("p",[t._v("让我们暂时将其放在一边。在"),s("RouterLink",{attrs:{to:"/ddia/ch3.html"}},[t._v("下一章")]),t._v("中，我们将讨论在"),s("strong",[t._v("实现")]),t._v("本章描述的数据模型时会遇到的一些权衡。")],1),t._v(" "),s("h2",{attrs:{id:"参考文献"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#参考文献"}},[t._v("#")]),t._v(" 参考文献")]),t._v(" "),s("ol",[s("li",[s("p",[t._v("Edgar F. Codd: “"),s("a",{attrs:{href:"https://www.seas.upenn.edu/~zives/03f/cis550/codd.pdf",target:"_blank",rel:"noopener noreferrer"}},[t._v("A Relational Model of Data for Large Shared Data Banks"),s("OutboundLink")],1),t._v(",” "),s("em",[t._v("Communications of the ACM")]),t._v(", volume 13, number 6, pages 377–387, June 1970. "),s("a",{attrs:{href:"http://dx.doi.org/10.1145/362384.362685",target:"_blank",rel:"noopener noreferrer"}},[t._v("doi:10.1145/362384.362685"),s("OutboundLink")],1)])]),t._v(" "),s("li",[s("p",[t._v("Michael Stonebraker and Joseph M. Hellerstein: “"),s("a",{attrs:{href:"http://mitpress2.mit.edu/books/chapters/0262693143chapm1.pdf",target:"_blank",rel:"noopener noreferrer"}},[t._v("What Goes Around Comes Around"),s("OutboundLink")],1),t._v(",”\nin "),s("em",[t._v("Readings in Database Systems")]),t._v(", 4th edition, MIT Press, pages 2–41, 2005. ISBN: 978-0-262-69314-1")])]),t._v(" "),s("li",[s("p",[t._v("Pramod J. Sadalage and Martin Fowler: "),s("em",[t._v("NoSQL Distilled")]),t._v(". Addison-Wesley, August 2012. ISBN:\n978-0-321-82662-6")])]),t._v(" "),s("li",[s("p",[t._v("Eric Evans: “"),s("a",{attrs:{href:"http://blog.sym-link.com/2009/10/30/nosql_whats_in_a_name.html",target:"_blank",rel:"noopener noreferrer"}},[t._v("NoSQL: What's in a Name?"),s("OutboundLink")],1),t._v(",” "),s("em",[t._v("blog.sym-link.com")]),t._v(", October 30, 2009.")])]),t._v(" "),s("li",[s("p",[t._v("James Phillips:  “"),s("a",{attrs:{href:"http://blog.couchbase.com/nosql-adoption-survey-surprises",target:"_blank",rel:"noopener noreferrer"}},[t._v("Surprises in Our NoSQL   Adoption Survey"),s("OutboundLink")],1),t._v(",” "),s("em",[t._v("blog.couchbase.com")]),t._v(", February 8, 2012.")])]),t._v(" "),s("li",[s("p",[t._v("Michael Wagner:  "),s("em",[t._v("SQL/XML:2006 – Evaluierung der Standardkonformität ausgewählter Datenbanksysteme")]),t._v(".  Diplomica Verlag, Hamburg, 2010. ISBN: 978-3-836-64609-3")])]),t._v(" "),s("li",[s("p",[t._v("“"),s("a",{attrs:{href:"http://technet.microsoft.com/en-us/library/bb522446.aspx",target:"_blank",rel:"noopener noreferrer"}},[t._v("XML   Data in SQL Server"),s("OutboundLink")],1),t._v(",” SQL Server 2012 documentation, "),s("em",[t._v("technet.microsoft.com")]),t._v(", 2013.")])]),t._v(" "),s("li",[s("p",[t._v("“"),s("a",{attrs:{href:"http://www.postgresql.org/docs/9.3/static/index.html",target:"_blank",rel:"noopener noreferrer"}},[t._v("PostgreSQL   9.3.1 Documentation"),s("OutboundLink")],1),t._v(",” The PostgreSQL Global Development Group, 2013.")])]),t._v(" "),s("li",[s("p",[t._v("“"),s("a",{attrs:{href:"http://docs.mongodb.org/manual/",target:"_blank",rel:"noopener noreferrer"}},[t._v("The MongoDB 2.4 Manual"),s("OutboundLink")],1),t._v(",” MongoDB, Inc., 2013.")])]),t._v(" "),s("li",[s("p",[t._v("“"),s("a",{attrs:{href:"http://www.rethinkdb.com/docs/",target:"_blank",rel:"noopener noreferrer"}},[t._v("RethinkDB 1.11 Documentation"),s("OutboundLink")],1),t._v(",” "),s("em",[t._v("rethinkdb.com")]),t._v(", 2013.")])]),t._v(" "),s("li",[s("p",[t._v("“"),s("a",{attrs:{href:"http://docs.couchdb.org/en/latest/",target:"_blank",rel:"noopener noreferrer"}},[t._v("Apache CouchDB 1.6 Documentation"),s("OutboundLink")],1),t._v(",” "),s("em",[t._v("docs.couchdb.org")]),t._v(", 2014.")])]),t._v(" "),s("li",[s("p",[t._v("Lin Qiao, Kapil Surlaker, Shirshanka Das, et al.: “"),s("a",{attrs:{href:"http://www.slideshare.net/amywtang/espresso-20952131",target:"_blank",rel:"noopener noreferrer"}},[t._v("On Brewing Fresh Espresso: LinkedIn’s Distributed Data Serving Platform"),s("OutboundLink")],1),t._v(",” at "),s("em",[t._v("ACM International Conference on Management of Data")]),t._v(" (SIGMOD), June 2013.")])]),t._v(" "),s("li",[s("p",[t._v("Rick Long, Mark Harrington, Robert Hain, and Geoff Nicholls: "),s("a",{attrs:{href:"http://www.redbooks.ibm.com/redbooks/pdfs/sg245352.pdf"}},[s("em",[t._v("IMS Primer")])]),t._v(". IBM Redbook SG24-5352-00, IBM International Technical Support Organization, January 2000.")])]),t._v(" "),s("li",[s("p",[t._v("Stephen D. Bartlett: “"),s("a",{attrs:{href:"ftp://public.dhe.ibm.com/software/data/ims/pdf/TCG2013015LI.pdf"}},[t._v("IBM’s IMS—Myths, Realities, and Opportunities")]),t._v(",” The Clipper Group Navigator, TCG2013015LI, July 2013.")])]),t._v(" "),s("li",[s("p",[t._v("Sarah Mei: “"),s("a",{attrs:{href:"http://www.sarahmei.com/blog/2013/11/11/why-you-should-never-use-mongodb/",target:"_blank",rel:"noopener noreferrer"}},[t._v("Why You Should Never Use MongoDB"),s("OutboundLink")],1),t._v(",” "),s("em",[t._v("sarahmei.com")]),t._v(", November 11, 2013.")])]),t._v(" "),s("li",[s("p",[t._v("J. S. Knowles and D. M. R. Bell: “The CODASYL Model,” in "),s("em",[t._v("Databases—Role and Structure: An Advanced Course")]),t._v(", edited by P. M. Stocker, P. M. D. Gray, and M. P. Atkinson, pages 19–56, Cambridge University Press, 1984. ISBN: 978-0-521-25430-4")])]),t._v(" "),s("li",[s("p",[t._v("Charles W. Bachman: “"),s("a",{attrs:{href:"http://dl.acm.org/citation.cfm?id=362534",target:"_blank",rel:"noopener noreferrer"}},[t._v("The Programmer as Navigator"),s("OutboundLink")],1),t._v(",” "),s("em",[t._v("Communications of the ACM")]),t._v(", volume 16, number 11, pages 653–658, November 1973. "),s("a",{attrs:{href:"http://dx.doi.org/10.1145/355611.362534",target:"_blank",rel:"noopener noreferrer"}},[t._v("doi:10.1145/355611.362534"),s("OutboundLink")],1)])]),t._v(" "),s("li",[s("p",[t._v("Joseph M. Hellerstein, Michael Stonebraker, and James Hamilton: “"),s("a",{attrs:{href:"http://db.cs.berkeley.edu/papers/fntdb07-architecture.pdf",target:"_blank",rel:"noopener noreferrer"}},[t._v("Architecture of a Database System"),s("OutboundLink")],1),t._v(",”\n"),s("em",[t._v("Foundations and Trends in Databases")]),t._v(", volume 1, number 2, pages 141–259, November 2007. "),s("a",{attrs:{href:"http://dx.doi.org/10.1561/1900000002",target:"_blank",rel:"noopener noreferrer"}},[t._v("doi:10.1561/1900000002"),s("OutboundLink")],1)])]),t._v(" "),s("li",[s("p",[t._v("Sandeep Parikh and Kelly Stirman: “"),s("a",{attrs:{href:"http://blog.mongodb.org/post/65517193370/schema-design-for-time-series-data-in-mongodb",target:"_blank",rel:"noopener noreferrer"}},[t._v("Schema Design for Time Series Data in MongoDB"),s("OutboundLink")],1),t._v(",” "),s("em",[t._v("blog.mongodb.org")]),t._v(", October 30, 2013.")])]),t._v(" "),s("li",[s("p",[t._v("Martin Fowler: “"),s("a",{attrs:{href:"http://martinfowler.com/articles/schemaless/",target:"_blank",rel:"noopener noreferrer"}},[t._v("Schemaless Data Structures"),s("OutboundLink")],1),t._v(",” "),s("em",[t._v("martinfowler.com")]),t._v(", January 7, 2013.")])]),t._v(" "),s("li",[s("p",[t._v("Amr Awadallah: “"),s("a",{attrs:{href:"http://www.slideshare.net/awadallah/schemaonread-vs-schemaonwrite",target:"_blank",rel:"noopener noreferrer"}},[t._v("Schema-on-Read vs. Schema-on-Write"),s("OutboundLink")],1),t._v(",” at "),s("em",[t._v("Berkeley EECS RAD Lab Retreat")]),t._v(", Santa Cruz, CA, May 2009.")])]),t._v(" "),s("li",[s("p",[t._v("Martin Odersky: “"),s("a",{attrs:{href:"http://www.infoq.com/presentations/data-types-issues",target:"_blank",rel:"noopener noreferrer"}},[t._v("The Trouble with Types"),s("OutboundLink")],1),t._v(",” at "),s("em",[t._v("Strange Loop")]),t._v(", September 2013.")])]),t._v(" "),s("li",[s("p",[t._v("Conrad Irwin: “"),s("a",{attrs:{href:"https://speakerdeck.com/conradirwin/mongodb-confessions-of-a-postgresql-lover",target:"_blank",rel:"noopener noreferrer"}},[t._v("MongoDB—Confessions of a PostgreSQL Lover"),s("OutboundLink")],1),t._v(",” at "),s("em",[t._v("HTML5DevConf")]),t._v(", October 2013.")])]),t._v(" "),s("li",[s("p",[t._v("“"),s("a",{attrs:{href:"http://www.percona.com/doc/percona-toolkit/2.2/pt-online-schema-change.html",target:"_blank",rel:"noopener noreferrer"}},[t._v("Percona Toolkit Documentation: pt-online-schema-change"),s("OutboundLink")],1),t._v(",” Percona Ireland Ltd., 2013.")])]),t._v(" "),s("li",[s("p",[t._v("Rany Keddo, Tobias Bielohlawek, and Tobias Schmidt: “"),s("a",{attrs:{href:"https://github.com/soundcloud/lhm",target:"_blank",rel:"noopener noreferrer"}},[t._v("Large Hadron Migrator"),s("OutboundLink")],1),t._v(",” SoundCloud, 2013. Shlomi Noach:")]),t._v(" "),s("p",[t._v("“"),s("a",{attrs:{href:"http://githubengineering.com/gh-ost-github-s-online-migration-tool-for-mysql/",target:"_blank",rel:"noopener noreferrer"}},[t._v("gh-ost: GitHub's Online Schema Migration Tool for MySQL"),s("OutboundLink")],1),t._v(",” "),s("em",[t._v("githubengineering.com")]),t._v(", August 1, 2016.")])]),t._v(" "),s("li",[s("p",[t._v("James C. Corbett, Jeffrey Dean, Michael Epstein, et al.: “"),s("a",{attrs:{href:"http://research.google.com/archive/spanner.html",target:"_blank",rel:"noopener noreferrer"}},[t._v("Spanner: Google’s Globally-Distributed Database"),s("OutboundLink")],1),t._v(",” at "),s("em",[t._v("10th USENIX Symposium on Operating System Design and Implementation")]),t._v(" (OSDI),\nOctober 2012.")])]),t._v(" "),s("li",[s("p",[t._v("Donald K. Burleson: “"),s("a",{attrs:{href:"http://www.dba-oracle.com/oracle_tip_hash_index_cluster_table.htm",target:"_blank",rel:"noopener noreferrer"}},[t._v("Reduce I/O with Oracle Cluster Tables"),s("OutboundLink")],1),t._v(",” "),s("em",[t._v("dba-oracle.com")]),t._v(".")])]),t._v(" "),s("li",[s("p",[t._v("Fay Chang, Jeffrey Dean, Sanjay Ghemawat, et al.: “"),s("a",{attrs:{href:"http://research.google.com/archive/bigtable.html",target:"_blank",rel:"noopener noreferrer"}},[t._v("Bigtable: A Distributed Storage System for Structured Data"),s("OutboundLink")],1),t._v(",” at "),s("em",[t._v("7th USENIX Symposium on Operating System Design and Implementation")]),t._v(" (OSDI), November 2006.")])]),t._v(" "),s("li",[s("p",[t._v("Bobbie J. Cochrane and Kathy A. McKnight: “"),s("a",{attrs:{href:"http://www.ibm.com/developerworks/data/library/techarticle/dm-1306nosqlforjson1/",target:"_blank",rel:"noopener noreferrer"}},[t._v("DB2 JSON Capabilities, Part 1: Introduction to DB2 JSON"),s("OutboundLink")],1),t._v(",” IBM developerWorks, June 20, 2013.")])]),t._v(" "),s("li",[s("p",[t._v("Herb Sutter: “"),s("a",{attrs:{href:"http://www.gotw.ca/publications/concurrency-ddj.htm",target:"_blank",rel:"noopener noreferrer"}},[t._v("The Free Lunch Is Over: A Fundamental Turn Toward Concurrency in Software"),s("OutboundLink")],1),t._v(",” "),s("em",[t._v("Dr. Dobb's Journal")]),t._v(", volume 30, number 3, pages 202-210, March 2005.")])]),t._v(" "),s("li",[s("p",[t._v("Joseph M. Hellerstein: “"),s("a",{attrs:{href:"http://www.eecs.berkeley.edu/Pubs/TechRpts/2010/EECS-2010-90.pdf",target:"_blank",rel:"noopener noreferrer"}},[t._v("The Declarative Imperative: Experiences and Conjectures in Distributed Logic"),s("OutboundLink")],1),t._v(",” Electrical Engineering and Computer Sciences, University of California at Berkeley, Tech report UCB/EECS-2010-90, June 2010.")])]),t._v(" "),s("li",[s("p",[t._v("Jeffrey Dean and Sanjay Ghemawat: “"),s("a",{attrs:{href:"http://research.google.com/archive/mapreduce.html",target:"_blank",rel:"noopener noreferrer"}},[t._v("MapReduce: Simplified Data Processing on Large Clusters"),s("OutboundLink")],1),t._v(",” at "),s("em",[t._v("6th USENIX Symposium on Operating System Design and Implementation")]),t._v(" (OSDI), December 2004.")])]),t._v(" "),s("li",[s("p",[t._v("Craig Kerstiens: “"),s("a",{attrs:{href:"https://blog.heroku.com/javascript_in_your_postgres",target:"_blank",rel:"noopener noreferrer"}},[t._v("JavaScript in Your Postgres"),s("OutboundLink")],1),t._v(",” "),s("em",[t._v("blog.heroku.com")]),t._v(", June 5, 2013.")])]),t._v(" "),s("li",[s("p",[t._v("Nathan Bronson, Zach Amsden, George Cabrera, et al.: “"),s("a",{attrs:{href:"https://www.usenix.org/conference/atc13/technical-sessions/presentation/bronson",target:"_blank",rel:"noopener noreferrer"}},[t._v("TAO: Facebook’s Distributed Data Store for the Social Graph"),s("OutboundLink")],1),t._v(",” at "),s("em",[t._v("USENIX Annual Technical Conference")]),t._v(" (USENIX ATC), June 2013.")])]),t._v(" "),s("li",[s("p",[t._v("“"),s("a",{attrs:{href:"http://tinkerpop.apache.org/docs/3.2.3/reference/",target:"_blank",rel:"noopener noreferrer"}},[t._v("Apache TinkerPop3.2.3 Documentation"),s("OutboundLink")],1),t._v(",” "),s("em",[t._v("tinkerpop.apache.org")]),t._v(", October 2016.")])]),t._v(" "),s("li",[s("p",[t._v("“"),s("a",{attrs:{href:"http://docs.neo4j.org/chunked/2.0.0/index.html",target:"_blank",rel:"noopener noreferrer"}},[t._v("The Neo4j Manual v2.0.0"),s("OutboundLink")],1),t._v(",” Neo Technology, 2013. Emil Eifrem: "),s("a",{attrs:{href:"https://twitter.com/emileifrem/status/419107961512804352",target:"_blank",rel:"noopener noreferrer"}},[t._v("Twitter correspondence"),s("OutboundLink")],1),t._v(", January 3, 2014.")])]),t._v(" "),s("li",[s("p",[t._v("David Beckett and Tim Berners-Lee: “"),s("a",{attrs:{href:"http://www.w3.org/TeamSubmission/turtle/",target:"_blank",rel:"noopener noreferrer"}},[t._v("Turtle – Terse RDF Triple Language"),s("OutboundLink")],1),t._v(",” W3C Team Submission, March 28, 2011.")])]),t._v(" "),s("li",[s("p",[t._v("“"),s("a",{attrs:{href:"http://docs.datomic.com/",target:"_blank",rel:"noopener noreferrer"}},[t._v("Datomic Development Resources"),s("OutboundLink")],1),t._v(",” Metadata Partners, LLC, 2013. W3C RDF Working Group: “"),s("a",{attrs:{href:"http://www.w3.org/RDF/",target:"_blank",rel:"noopener noreferrer"}},[t._v("Resource Description Framework (RDF)"),s("OutboundLink")],1),t._v(",” "),s("em",[t._v("w3.org")]),t._v(", 10 February 2004.")])]),t._v(" "),s("li",[s("p",[t._v("“"),s("a",{attrs:{href:"http://jena.apache.org/",target:"_blank",rel:"noopener noreferrer"}},[t._v("Apache Jena"),s("OutboundLink")],1),t._v(",” Apache Software Foundation.")])]),t._v(" "),s("li",[s("p",[t._v("Steve Harris, Andy Seaborne, and Eric Prud'hommeaux: “"),s("a",{attrs:{href:"http://www.w3.org/TR/sparql11-query/",target:"_blank",rel:"noopener noreferrer"}},[t._v("SPARQL 1.1 Query Language"),s("OutboundLink")],1),t._v(",”\nW3C Recommendation, March 2013.")])]),t._v(" "),s("li",[s("p",[t._v("Todd J. Green, Shan Shan Huang, Boon Thau Loo, and Wenchao Zhou: “"),s("a",{attrs:{href:"http://blogs.evergreen.edu/sosw/files/2014/04/Green-Vol5-DBS-017.pdf",target:"_blank",rel:"noopener noreferrer"}},[t._v("Datalog and Recursive Query Processing"),s("OutboundLink")],1),t._v(",” "),s("em",[t._v("Foundations and Trends in Databases")]),t._v(", volume 5, number 2, pages 105–195, November 2013. "),s("a",{attrs:{href:"http://dx.doi.org/10.1561/1900000017",target:"_blank",rel:"noopener noreferrer"}},[t._v("doi:10.1561/1900000017"),s("OutboundLink")],1)])]),t._v(" "),s("li",[s("p",[t._v("Stefano Ceri, Georg Gottlob, and Letizia Tanca: “"),s("a",{attrs:{href:"https://www.researchgate.net/profile/Letizia_Tanca/publication/3296132_What_you_always_wanted_to_know_about_Datalog_and_never_dared_to_ask/links/0fcfd50ca2d20473ca000000.pdf",target:"_blank",rel:"noopener noreferrer"}},[t._v("What You Always Wanted to Know About Datalog (And Never Dared to Ask)"),s("OutboundLink")],1),t._v(",” "),s("em",[t._v("IEEE Transactions on Knowledge and Data Engineering")]),t._v(", volume 1, number 1, pages 146–166, March 1989. "),s("a",{attrs:{href:"http://dx.doi.org/10.1109/69.43410",target:"_blank",rel:"noopener noreferrer"}},[t._v("doi:10.1109/69.43410"),s("OutboundLink")],1)])]),t._v(" "),s("li",[s("p",[t._v("Serge Abiteboul, Richard Hull, and Victor Vianu: "),s("a",{attrs:{href:"http://webdam.inria.fr/Alice/"}},[s("em",[t._v("Foundations of Databases")])]),t._v(". Addison-Wesley, 1995. ISBN: 978-0-201-53771-0, available online at "),s("em",[t._v("webdam.inria.fr/Alice")])])]),t._v(" "),s("li",[s("p",[t._v("Nathan Marz: “"),s("a",{attrs:{href:"http://cascalog.org/",target:"_blank",rel:"noopener noreferrer"}},[t._v("Cascalog"),s("OutboundLink")],1),t._v('," '),s("em",[t._v("cascalog.org")]),t._v(". Dennis A. Benson,  Ilene Karsch-Mizrachi, David J. Lipman, et al.:")]),t._v(" "),s("p",[t._v("“"),s("a",{attrs:{href:"http://nar.oxfordjournals.org/content/36/suppl_1/D25.full-text-lowres.pdf",target:"_blank",rel:"noopener noreferrer"}},[t._v("GenBank"),s("OutboundLink")],1),t._v(",”   "),s("em",[t._v("Nucleic Acids Research")]),t._v(", volume 36, Database issue, pages D25–D30, December 2007.   "),s("a",{attrs:{href:"http://dx.doi.org/10.1093/nar/gkm929",target:"_blank",rel:"noopener noreferrer"}},[t._v("doi:10.1093/nar/gkm929"),s("OutboundLink")],1)])]),t._v(" "),s("li",[s("p",[t._v("Fons Rademakers:   “"),s("a",{attrs:{href:"http://indico.cern.ch/getFile.py/access?contribId=13&resId=0&materialId=slides&confId=246453",target:"_blank",rel:"noopener noreferrer"}},[t._v("ROOT   for Big Data Analysis"),s("OutboundLink")],1),t._v(",” at "),s("em",[t._v("Workshop on the Future of Big Data Management")]),t._v(",\nLondon, UK, June 2013.")])])]),t._v(" "),s("hr"),t._v(" "),s("table",[s("thead",[s("tr",[s("th",[t._v("上一章")]),t._v(" "),s("th",[t._v("目录")]),t._v(" "),s("th",[t._v("下一章")])])]),t._v(" "),s("tbody",[s("tr",[s("td",[s("RouterLink",{attrs:{to:"/ddia/ch1.html"}},[t._v("第一章：可靠、可扩展、可维护")])],1),t._v(" "),s("td",[s("RouterLink",{attrs:{to:"/ddia/"}},[t._v("设计数据密集型应用")])],1),t._v(" "),s("td",[s("RouterLink",{attrs:{to:"/ddia/ch3.html"}},[t._v("第三章：存储与检索")])],1)])])])])}),[],!1,null,null,null);a.default=e.exports}}]);